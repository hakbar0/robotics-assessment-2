{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81b92453",
   "metadata": {},
   "source": [
    "Author: Abdulrahman Altahhan, Jan 2023.\n",
    "\n",
    "The notebook use a library of functionality in RL that aims for simplicity and general insight into how algorithms work, these libraries are written from scratch using standard python libraries (numpy, matplotlib etc.).\n",
    "Please note that you will need to take a permission from the author to use the code for research, commercially or otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ae6ef3",
   "metadata": {},
   "source": [
    "# Lesson 3- Dynamic Programming: Model-Based Approach\n",
    "\n",
    "**Learning outcomes**\n",
    "1. understand what we mean by the dynamics of the environment\n",
    "2. understand how the environment's dynamics are used in the Bellman equation\n",
    "3. use the dynamics to estimate the value function and the action-value function via dynamic programming \n",
    "4. understand the policy improvement theorem\n",
    "5. understand the policy-iteration and value-iteration algorithms as the backbone of many RL algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5f1ca1",
   "metadata": {},
   "source": [
    "In the first lesson, you looked at a basic RL problem, the k-arm bandit, which involves only actions and no states (non-associative problem). In general, in RL, we are faced with different situations, and we need to take different actions in each situation in order to achieve a certain goal. This general type of environment with states and actions imposes a different flavour to the solution we can design. From now on, we will tackle associative problems. For associative problems, there are two approaches:\n",
    "\n",
    "1. Model-based approach\n",
    "2. Model-free approach\n",
    "\n",
    "In this lesson, we will take the first approach. We will learn how to use a model of the environment to solve an RL problem. The model is given in the form of the dynamics of the environment. These usually come in the form of 4 dimensions of conditional probability involving an answer to the following question: what is the probability of obtaining a certain reward r in a certain state s' given that the agent was previously in a state s and applied action a.\n",
    "\n",
    "We will assume that there is already a model for the environment and try to take advantage of this model to come up with the best policy. Nevertheless, we will see simple ways to build such models and come back to this question later when we tackle planning algorithms in RL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff0ad52",
   "metadata": {},
   "source": [
    "**Reading**:\n",
    "The accompanying reading of this lesson are **chapters 3 and 4** from our text book by Sutton and Barto available online [here](http://incompleteideas.net/book/RLbook2020.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba261a3",
   "metadata": {},
   "source": [
    "**Plan**\n",
    "As usual, in general there are two types of RL problems that we will attempt to design methods to deal with \n",
    "1. Prediction problem\n",
    "For These problems we will design Policy Evaluation Methods that attempt to find the best estimate for the value-function given a policy.\n",
    "\n",
    "\n",
    "2. Control problems \n",
    "For These problems we will design Value Iteration methods which utilise the idea of Generalised Policy Iteration. They attempt to find the best policy, via estimating an action-value function for a current policy then moving to a better and improved policy by choosing a greedy action often.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "964aa507",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4433e98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from Lesson2_GridWorldMDPs import * #Grid, randwalk, grid, cliffwalk, windy, cliffwalk, maze, maze8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dc74e3",
   "metadata": {},
   "source": [
    "We start by generating conditional probabilities from random joint probabilities, then we move into generating them from a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df0b1e5",
   "metadata": {},
   "source": [
    "## 1D Probability\n",
    "Let us start by defining a 1D probability function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ca14d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35513626 0.29148414 0.008207   0.03123475 0.31393786] 1.0\n"
     ]
    }
   ],
   "source": [
    "def P(nS):\n",
    "    p = np.zeros(nS)\n",
    "    for s in range(nS):\n",
    "        p[s] = rand()\n",
    "        \n",
    "    return p/p.sum()\n",
    "p = P(5)\n",
    "print(p, p.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcf017d",
   "metadata": {},
   "source": [
    "## 2D Probability: Joint Probability\n",
    "Let us move to defining a joint probability function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0a2f6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13859115 0.13435588]\n",
      " [0.05054938 0.14326937]\n",
      " [0.13463159 0.07785564]\n",
      " [0.09074469 0.01708724]\n",
      " [0.10158592 0.11132915]] 1.0\n"
     ]
    }
   ],
   "source": [
    "def P(nS,nA):\n",
    "    p = np.zeros((nS,nA))\n",
    "    for s in range(nS):\n",
    "        for a in range(nA):\n",
    "            p[s,a] = rand()\n",
    "            \n",
    "        \n",
    "    # /p.sum() to make sure that this is a joint probability density, i.e. p.sum()==1\n",
    "    return p/p.sum() \n",
    "p = P(5,2)\n",
    "print(p, p.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571717df",
   "metadata": {},
   "source": [
    "Note that p[s,a] in the above is interpreted as the probability of being in state *s* and taking action *a* at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f7f19e",
   "metadata": {},
   "source": [
    "## 2D Probability: Conditional Probability\n",
    "Let us move to defining a conditional probability function. Remember that a conditional probability must satisfy that Bayes rule.\n",
    "\n",
    "In the below pr[sn,a] is interpreted as pr[sn|a] the probability of moving to state sn given that we took action a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "226157a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.31867449 0.23421998]\n",
      " [0.23175184 0.20671174]\n",
      " [0.13190003 0.30968032]\n",
      " [0.10519547 0.24294188]\n",
      " [0.21247818 0.00644607]]\n",
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "def P(nS,nA):\n",
    "    pr = np.zeros((nS,nA)) # joint\n",
    "    p  = np.zeros((nS,nA)) # conditional\n",
    "    \n",
    "    # first create a joint probability\n",
    "    for sn in range(nS):\n",
    "        for a in range(nA):\n",
    "            pr[sn,a] = rand()\n",
    "\n",
    "    # to make sure that this is a joint probability density\n",
    "    pr=pr/pr.sum() \n",
    "    \n",
    "    # now create a conditional probability via Bayes rule\n",
    "    for a in range(nA):\n",
    "        p[:,a] = pr[:,a]/pr[:,a].sum()\n",
    "            \n",
    "            \n",
    "    return p\n",
    "\n",
    "p = P(5,2)\n",
    "print(p)\n",
    "print(p.sum(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd12f07d",
   "metadata": {},
   "source": [
    "## 4D Probability: Random Dynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcc5adf",
   "metadata": {},
   "source": [
    "Our goal now is to be able to obtain a probability that can represent a random environment dynamics. Such a probability has the form of p[sn,rn | s,a] which represents the probability of moving to next state sn and obtaining the reward rn given that the agent was in state s and took action a.\n",
    "\n",
    "We generalise the above method of obtaining conditional probabilities from random joint probability density to 4-d. We have not dealt with 3-d cases for brevity. This time we will make it a bit more efficient by avoiding the four for loops and utilising the vectorised version of the rand() function in numpy and we convert to a conditional in-place to avoid having two probabilities p and pr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb0143ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.32046774 0.26616449]\n",
      "   [0.0976896  0.00035689]\n",
      "   [0.26008775 0.19550748]]\n",
      "\n",
      "  [[0.03013506 0.03301488]\n",
      "   [0.30733709 0.21549492]\n",
      "   [0.00581461 0.17453613]]]\n",
      "\n",
      "\n",
      " [[[0.11984678 0.18982569]\n",
      "   [0.21331026 0.04930323]\n",
      "   [0.29765206 0.19934832]]\n",
      "\n",
      "  [[0.23475825 0.27352042]\n",
      "   [0.09998503 0.26218639]\n",
      "   [0.10319729 0.02678356]]]\n",
      "\n",
      "\n",
      " [[[0.13053225 0.12565188]\n",
      "   [0.15617915 0.203724  ]\n",
      "   [0.12914727 0.25886976]]\n",
      "\n",
      "  [[0.16425992 0.11182264]\n",
      "   [0.12549887 0.26893457]\n",
      "   [0.20410102 0.14495475]]]]\n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "def dynrand(nS, nA, nR): # states, actions, rewards dimensions \n",
    "    #first joint: p[sn,rn, s,a]\n",
    "    p  = np.random.rand(nS,nR,  nS,nA)\n",
    "    p /= p.sum()\n",
    "    \n",
    "    #convert it to conditional: p[sn,rn| s,a] \n",
    "    for s in range(nS):\n",
    "        for a in range(nA):\n",
    "            p[:,:, s,a] /= p[:,:, s,a].sum()\n",
    "        \n",
    "    return p\n",
    "\n",
    "p = dynrand(3,2,2)\n",
    "print(p)\n",
    "print(p.sum(0).sum(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beed1b3f",
   "metadata": {},
   "source": [
    "## Inducing the dynamics by interacting with the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd0fd6b",
   "metadata": {},
   "source": [
    "Now we move into obtaining the dynamics form an actual environment instead of generating the dynamics randomly as we did earlier.\n",
    "\n",
    "We will use mainly the random walk environment and the grid world environment and generate their dynamics. These are deterministic simple environments. Nevertheless, they are very useful to demonstrate the ideas of RL. \n",
    "\n",
    "Note that when we move to the real world the dynamics becomes much more complex and building or obtaining the dynamic becomes impractical form most cases. Therefore, towards that end instead of dealing directly with the environment dynamics we will see later how we can substitute this requirement by having to *interact* with the environment to gain *experience* which will help us *infer* a good *estimate* of the *expected* value function (discounted sum of rewards) which in turn will help us to *infer* a close to *optimal policy* for the task in hand. \n",
    "\n",
    "The exercise of dealing with probabilities and then using it in designing a Dynamic Programming solution is valuable since most of other solutions utilise the basic ideas (policy iteration, value iteration algorithms and policy improvements theorem) that we cover here and will mainly show us that we can devise a from of Bellman equation that is suitable for interaction instead of probabilities.\n",
    "\n",
    "Dynamic programming suffers from what Bellman described as the curse of dimensionality which basically dictates that the computational resources required to solve a problem grows exponentially with the dimensionality of the problem. So in our case the dimensionality is the number of states (as well as actions and rewards). So for example if the dynamic programming solution computational complexity is $2^{|S|}$ and the number of states $|S|=10$ then it costs $2^{10}=1024$ but when the number of states $|S|$ grows to 100 the cost become $2^{100}=1267650600228229401496703205376$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5f18a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "1267650600228229401496703205376\n"
     ]
    }
   ],
   "source": [
    "print(2**10)\n",
    "print(2**100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e625ad3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dynamics(env=randwalk(), show=True, stoch=True, repeat=1000 ): #, maxjump=1\n",
    "    rewards = env.rewards_set()\n",
    "    nS, nA, nR = env.nS, env.nA, rewards.shape[0]\n",
    "    p  = np.zeros((nS,nR,  nS,nA))\n",
    "    \n",
    "    for i in range(repeat if not stoch else 1): # in case the env is stochastic (non-deterministic)\n",
    "        for s in range(nS):\n",
    "            for a in range(nA):\n",
    "                if not i and show: env.render() # render the first repitition only\n",
    "                env.s = s\n",
    "                sn,rn,_,_ = env.step(a)\n",
    "                rd = np.where(rewards==rn)[0][0] # get which reward index we need to update\n",
    "                #if (s!=sn) ^ (s in env.goals): p[sn,rd, s,a] +=1 # xor this would give terminal states a pr 1!\n",
    "                if (s!=sn) and not (s in env.goals): p[sn,rd, s,a] +=1\n",
    "            \n",
    "    # making sure that it is a conditional probability that satisfies Bayes rule\n",
    "    for s in range(nS):\n",
    "        for a in range(nA):\n",
    "            sm=p[:,:, s,a].sum()\n",
    "            if sm: p[:,:, s,a] /= sm\n",
    "            \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb586cc",
   "metadata": {},
   "source": [
    "Note that states and actions can be immediately interpreted as indexes, rewards on the other hand are allowed to be real values. Therefore, we need to obtain the index of the reward value that we need to update since p[sn, rn, s,a] expects an index in rn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91915422",
   "metadata": {},
   "source": [
    "Let us now test our dynamics extraction procedure on a deterministic random walk environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "effed4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAApCAYAAADTTVdWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAFJElEQVR4nO3dX0hUaRzG8e8xbURHEWQ1tsCSqTBEliSZsTuHArva1Tsvc+mPdhNFVyUtgYEXwlDb1RoRghexy1JQhESEoOQf0mAjLNAlENSMQB1yRjx78baHnB2n3eicM6vPBw4y874vPhe+P89533fUsm0bERGAHL8DiEj2UEEQEYcKgog4VBBExKGCICIOFQQRceRmaiwpKbFDoZBXWTJaXl6msLDQ7xiObMqjLOkpS3pjY2Nvbdv+Jm2jbdsbXvv27bOzxePHj/2OsE425VGW9JQlPWDU3mDO65FBRBwqCCLi8LwgzM7OcvbsWfbu3Ut+fj5lZWXU19dz7do1lpaWvI4jKebn52lra2P37t0EAgHKy8uJRqP09/f7HU1SuDGXMi4qfm3T09McPnyY4uJirly5Qk1NDWtra0xOTnL79m1KS0tpaWnxMpKkaG5uJh6P09PTQygUYm5ujidPnrCwsOB3NG/ZNgwNwfAwLC5CURHU1UEkApbldzrX5pKnBeH06dPk5OQwOjq6bsW1urqapqYmbH3Qylfv379nYGCA/v5+otEoABUVFRw6dMjnZB5KJqGnB7q6YG7OvE4mIS/PXGVlcOECtLaa1z5xay559sjw7t07Hj58SHt7+4bbL1YWVN6tLBgMEgwGuXv3Lh8+fPA7jveWlqChAc6dg6kpWF6GRMLcLSQS5vXUlGmPRk1/H7g5lzwrCK9evcK2bfbv37/u/V27djk/iKdOnfIqjqSRm5vLrVu36O3tpaSkhEgkwvnz53n69Knf0dyXTEJjI4yMQDyeuW88bh4ljh0z4zzm5lzyfZdhYGCA8fFx6urqtuZvpSzT3NzMzMwM9+7do7GxkcHBQcLhMJ2dnX5Hc1dPD78MD1O9ssLNNM1JoAmoB6YBVlZgbAxupuvtj68xlzwrCKFQCMuyePny5br39+zZQygUoqCgwKso8hn5+fkcOXKEjo4OBgcHaW1t5fLlyyQSCb+jucO2oauL3xIJxoBf03SZAKqAnz5tj8fNWoPHa19uziXPCkJpaSlHjx7l+vXr2l78nzlw4ACrq6ub9w5uaAjm5vgeOAj8kKZLDfAH0JHaPjtrxnvIzbnk6SPDjRs3WFtbo7a2lr6+Pl68eMHk5CR9fX1MTEywbds2L+NIioWFBRoaGujt7eX58+dMTU1x584durq6iEajFBcX+x3RHcPDkExyAjPpf0zTZTvwOzAEVH7asLpq1h085tZc8nTbsbKykmfPnnH16lUuXbrEmzdvyMvLo6qqira2Ns6cOeNlHEkRDAYJh8PEYjFev37NysoKO3fupKWlhYsXL/odzz2Li1++OJhImPEec2sueVoQAHbs2EEsFiMWi3n9reUzAoEAnZ2dm38BMVVRkTlT8CVrJNu3m/E+cGMu+b7LIOK7urp/HDL6Gfju4zWTaWxuLmyig1sqCCKRiDmB+Il2YPzj9W2mseXlZvwmoYIgYlnmOPJ/3a4rKDDjNtEJWxUEETCfTTh4EAKBf9c/EIDaWjh+3N1cHlNBEAGzhvDggVlP+NydQkGB6Xf/vq8fcHKDCoLI34JBePQIuruhshIKC82dgGWZr4WF5v3ubtMvGPQ78Vfn+bajSFbLy4OTJ+HECXMCcWRk/d9DCIc31ZpBKhUEkXQsC+rrzbWF6JFBRBwqCCLiUEEQEYcKgog4rEx/jNGyrHngT+/iiIgHKuwN/pVbxoIgIluLHhlExKGCICIOFQQRcaggiIhDBUFEHH8B7THOg20/kucAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x36 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 2, 7, 2)\n",
      "[[0. 0.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "p = dynamics(env=randwalk())\n",
    "print(p.shape)\n",
    "print(p.sum(0).sum(0))\n",
    "# print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7422958c",
   "metadata": {},
   "source": [
    "The above shows that the probabilities of agent having been in state 0:6 (rows) and have gone left (column 0) all sum up to 1 except for the last terminal state 6 because once the agent is there it stays there and cannot move left. Also it shows equally that the probabilities of agent having been in state 0:6 and have gone right (column 1) all sum up to 1 except for the first terminal state 0 because once the agent is there it stays there and cannot move right. \n",
    "\n",
    "To further explain and dissect the generated probability dynamics we examine different states probabilities with different rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c21dcd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dynamcis(s):\n",
    "    print('-----------------------------Agent was in non-terminal state %d---------------------------------'%s)\n",
    "    print('Pr[of moving to states 0:6 and obtaining reward 0 |give agent was in state %d and moved left(0)]'%s)\n",
    "    print(p[:,0, s,0])\n",
    "\n",
    "    print('Pr[of moving to states 0:6 and obtaining reward 0 |give agent was in state %d and moved right(1)]'%s)\n",
    "    print(p[:,0, s,1])\n",
    "\n",
    "    print('Pr[of moving to states 0:6 and obtaining reward 1 |give agent was in state %d and moved left(0)]'%s)\n",
    "    print(p[:,1, s,0])\n",
    "\n",
    "    print('Pr[of moving to states 0:6 and obtaining reward 1 |give agent was in state %d and moved right(1)]'%s)\n",
    "    print(p[:,1, s,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c54fdc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------Agent was in non-terminal state 2---------------------------------\n",
      "Pr[of moving to states 0:6 and obtaining reward 0 |give agent was in state 2 and moved left(0)]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "Pr[of moving to states 0:6 and obtaining reward 0 |give agent was in state 2 and moved right(1)]\n",
      "[0. 0. 0. 1. 0. 0. 0.]\n",
      "Pr[of moving to states 0:6 and obtaining reward 1 |give agent was in state 2 and moved left(0)]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "Pr[of moving to states 0:6 and obtaining reward 1 |give agent was in state 2 and moved right(1)]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print_dynamcis(s=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "401489ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------Agent was in non-terminal state 5---------------------------------\n",
      "Pr[of moving to states 0:6 and obtaining reward 0 |give agent was in state 5 and moved left(0)]\n",
      "[0. 0. 0. 0. 1. 0. 0.]\n",
      "Pr[of moving to states 0:6 and obtaining reward 0 |give agent was in state 5 and moved right(1)]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "Pr[of moving to states 0:6 and obtaining reward 1 |give agent was in state 5 and moved left(0)]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "Pr[of moving to states 0:6 and obtaining reward 1 |give agent was in state 5 and moved right(1)]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print_dynamcis(s=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb72e4d1",
   "metadata": {},
   "source": [
    "Note that the probability of the penultimate state is a bit different than a mid-state such as 2. The reason is that when the agent move left it will get a 0 reward while when it moves right it will get a reward of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9872032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------Agent was in non-terminal state 0---------------------------------\n",
      "Pr[of moving to states 0:6 and obtaining reward 0 |give agent was in state 0 and moved left(0)]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "Pr[of moving to states 0:6 and obtaining reward 0 |give agent was in state 0 and moved right(1)]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "Pr[of moving to states 0:6 and obtaining reward 1 |give agent was in state 0 and moved left(0)]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "Pr[of moving to states 0:6 and obtaining reward 1 |give agent was in state 0 and moved right(1)]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print_dynamcis(s=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd68e839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------Agent was in non-terminal state 6---------------------------------\n",
      "Pr[of moving to states 0:6 and obtaining reward 0 |give agent was in state 6 and moved left(0)]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "Pr[of moving to states 0:6 and obtaining reward 0 |give agent was in state 6 and moved right(1)]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "Pr[of moving to states 0:6 and obtaining reward 1 |give agent was in state 6 and moved left(0)]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "Pr[of moving to states 0:6 and obtaining reward 1 |give agent was in state 6 and moved right(1)]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print_dynamcis(s=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e0f514",
   "metadata": {},
   "source": [
    "Uncomment the xor relationship and see the effect on the resultant policy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f6069c",
   "metadata": {},
   "source": [
    "## Accommodating for jumps in the environment\n",
    "Some environments might allow the agent to jump over some obstacles or simply skip cells. For these we define a slightly altered dynamics to take the jumps into account. Below we show the definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41091ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamics(env=randwalk(), show=True, stoch=False, repeat=1000): # , maxjump=1\n",
    "\n",
    "    rewards = env.rewards_set()\n",
    "    nS, nA, nR = env.nS, env.nA, rewards.shape[0]\n",
    "    p  = np.zeros((nS,nR,  nS,nA))\n",
    "    randjump = env.randjump\n",
    "    env.randjump = False # this is needed so that the probability calculations of all intermediate jumps is correctly calculated\n",
    "    for i in trange(repeat if stoch else 1): # in case the env is stochastic (non-deterministic)\n",
    "        for s in range(nS):\n",
    "            for a in range(nA):\n",
    "                for jump in (range(1,env.jump+1) if randjump else [env.jump]):\n",
    "                    if not i and show: env.render() # render the first repitition only\n",
    "                    env.s = s\n",
    "                    env.jump = jump\n",
    "                    rn = env.step(a)[1]\n",
    "                    sn = env.s\n",
    "                    rd = np.where(rewards==rn)[0][0] # get which reward index we need to update\n",
    "                    #if (s!=sn) ^ (s in env.goals): p[sn,rd, s,a] +=1 # xor this would give terminal states a pr 1!\n",
    "                    if (s!=sn) and not (s in env.goals): p[sn,rd, s,a] +=1\n",
    "    env.randjump = randjump\n",
    "    # making sure that it is a conditional probability that satisfies Bayes rule\n",
    "    for s in range(nS):\n",
    "        for a in range(nA):\n",
    "            sm=p[:,:, s,a].sum()\n",
    "            if sm: p[:,:, s,a] /= sm\n",
    "            \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a6a1e4",
   "metadata": {},
   "source": [
    "### State-Transition probability: reward marginalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca847ac",
   "metadata": {},
   "source": [
    "Now that we have induced the dynamics from the *environment*, we are ready to infer the state-transition probability from the *dynamics*.  Note that many older papers of RL refer to the 3-d state-transition probability without referring to the 4-d dynamics. The state-transition probability p[sn | s,a] is a conditional probability that specifies the probability of moving to the next state sn given that the agent was in state s and applied action a regardless of the rewards. In other words, the state-transition probability does not refer to the reward altogether. Therefore, all we have to do to infer it from the dynamics is to marginalise the dynamics with respect to the reward, which is what the below code snippet is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "599bc7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state-transition probability induced from the dynamics\n",
    "def ssa(p): \n",
    "    # states dim, action dim\n",
    "    nS, nA = p.shape[0], p.shape[3]\n",
    "    tr = np.zeros((nS, nS, nA))\n",
    "    for s in range(nS):\n",
    "        for a in range(nA):\n",
    "            for sn in range(nS):\n",
    "                tr[sn, s,a] = p[sn,:,s,a].sum()\n",
    "    return tr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db076617",
   "metadata": {},
   "source": [
    "Let us now apply this function on the obtained random walk dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "410426fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "tr = ssa(p)\n",
    "print(tr.sum(0))\n",
    "# print(tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ccc979",
   "metadata": {},
   "source": [
    "Again the state-transition probability satisfies similar properties of the dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5cf7d8",
   "metadata": {},
   "source": [
    "Finally, we can apply a similar logic to obtain the reward function, see page 49 of the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa21b32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reward function induced from the dynamics\n",
    "def rsa(p, rewards):\n",
    "    # state dim, reward dim\n",
    "    nS, nA, nR = p.shape[0], p.shape[3], p.shape[1]\n",
    "    r = np.zeros((nS,nA))\n",
    "    for s in range(nS):\n",
    "        for a in range(nA):\n",
    "             for rd, rn in enumerate(rewards):\n",
    "                r[s,a] += rn*p[:,rd, s,a].sum()\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d06ea75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 1.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "rewards = randwalk().rewards_set()\n",
    "r = rsa(p, rewards)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4043aaf5",
   "metadata": {},
   "source": [
    "This shows us that the expected reward of state-aciton pair (5,right)=1 and (6,right)=1. This is because we expect the agent to obtain a reward of 1 in the future when it move right while it was in state 5 because it will end up in the right terminal state which has a reward of 1. Also we have (6,right)=1 because once the agent is at the terminal state 6 it will stay there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcf0ba4",
   "metadata": {},
   "source": [
    "# Dynamic Programming Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b038b1",
   "metadata": {},
   "source": [
    "Ok so we are ready now to move to Dynamic programming algorithms to solve the RL problem of finding a best estimate of a value function and or finding an optimal policy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586865f3",
   "metadata": {},
   "source": [
    "## Policy evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4399b069",
   "metadata": {},
   "source": [
    "The first step to improving any policy is to evaluate how good or bad the policy is for the given task. This fundamental question can be addressed by tying up the task with a reward function that basically rewards the agent for achieving the task or a subtask that leads to the final goal. The agent's aim then becomes to collect as many rewards as possible (or to incur as few losses as possible), which should help the agent achieve the given task. One example is when a robot is moving in an environment, and we want it to reach a specific location, then we can reward/punish the robot for each step that is taking it close to the goal or away from it. But this awareness of the goal location is usually difficult to attain in real environments. Hence it is replaced by rewarding the agent when it reaches the goal or punishing the agent for each step taken without reaching the goal location.\n",
    "\n",
    "We can devise an evaluation strategy based on the discounted sum of rewards the agent is *expected* to collect while executing the task. The strategy depends on the dynamics of the environment. You may want to read section 4.1 and come back here to continue reading the code for the policy evaluation algorithm to get an insight into how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7227f313",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1) # change the seed to get a different dynamics\n",
    "\n",
    "def Policy_evaluation(env=randwalk(), π=None, p=None, show=True, v0=.01, V0=None, θ=1e-3, γ=1, \n",
    "                      isrand=False, stoch=False): \n",
    "    nS, nA, nR = env.nS, env.nA, env.nR\n",
    "    \n",
    "    # m states, k actions and d rewards returns a 4-d dynamics\n",
    "    if isrand:      p = dynrand(nS, nA, nR);          rewards = [-1,1] \n",
    "    elif p is None: p = dynamics(env=env, show=show, stoch=stoch); rewards = env.rewards_set() #maxjump=maxjump\n",
    "    else:                                             rewards = env.rewards_set()# obtain a model of the env\n",
    "        \n",
    "    #V  = np.ones(nS )*v0; V[env.goals] = 0 \n",
    "    V = np.ones(nS )*v0 if V0 is None else V0.copy()\n",
    "    V[env.goals] = 0 \n",
    "\n",
    "    #if π is None: π=np.zeros((nS, nA), dtype=np.uint32); π[:,1]=1 \n",
    "    if π is None: π=np.ones(nS, dtype=np.uint32) # if π is not passed then always move right\n",
    "    i=0\n",
    "    # policy evaluation--------------------------------------------------------------\n",
    "    while True:\n",
    "        Δ = 0\n",
    "        i+= 1\n",
    "        if not show: clear_output(wait=True); rng = trange(nS) # show some further indication to keep use infromed\n",
    "        else: rng = range(nS)\n",
    "        for s in rng:\n",
    "            v, V[s] = V[s], 0            \n",
    "            for sn in range(nS):\n",
    "                for rn, r in enumerate(rewards):\n",
    "                        if π.ndim == 1: V[s] += p[sn,rn, s,π[s]]*(r + γ*V[sn])# deterministic policy\n",
    "                        else:\n",
    "                            for a in range(nA): V[s] += π[s,a]*p[sn,rn, s,a]*(r + γ*V[sn]) # probabilistic policy              \n",
    "            Δ = max(Δ, abs(v-V[s]))\n",
    "        if Δ<θ:\n",
    "            if show: print('policy evaluation stopped @ iteration %d:'%i)\n",
    "            break\n",
    "    \n",
    "    return V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de89ea89",
   "metadata": {},
   "source": [
    "Note that we assume that when the policy is deterministic, it takes the shape (nS,) and its entries are actions ex. π[s]=1 means take right(1) when in state s.\n",
    "\n",
    "On the other hand if the policy is probabilistic, it has a shape of (nS, nA) and its entries are probabilities of each action given a state s, i.e π[a|s] written as π[s,a] in the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8989c74f",
   "metadata": {},
   "source": [
    "Note that γ must be < 1 to guarantee convergence of the Bellman equation because we do not know whether the policy guarantees reaching a terminal(goal) state. This condition can be relaxed when we move to sampling instead of dynamic programming in the next consequent lessons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bf88bd",
   "metadata": {},
   "source": [
    "Ok, let us test our policy evaluation method on a default policy where the agent goes right always (embedded in the code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "554b4f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAApCAYAAADTTVdWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAFJElEQVR4nO3dX0hUaRzG8e8xbURHEWQ1tsCSqTBEliSZsTuHArva1Tsvc+mPdhNFVyUtgYEXwlDb1RoRghexy1JQhESEoOQf0mAjLNAlENSMQB1yRjx78baHnB2n3eicM6vPBw4y874vPhe+P89533fUsm0bERGAHL8DiEj2UEEQEYcKgog4VBBExKGCICIOFQQRceRmaiwpKbFDoZBXWTJaXl6msLDQ7xiObMqjLOkpS3pjY2Nvbdv+Jm2jbdsbXvv27bOzxePHj/2OsE425VGW9JQlPWDU3mDO65FBRBwqCCLi8LwgzM7OcvbsWfbu3Ut+fj5lZWXU19dz7do1lpaWvI4jKebn52lra2P37t0EAgHKy8uJRqP09/f7HU1SuDGXMi4qfm3T09McPnyY4uJirly5Qk1NDWtra0xOTnL79m1KS0tpaWnxMpKkaG5uJh6P09PTQygUYm5ujidPnrCwsOB3NG/ZNgwNwfAwLC5CURHU1UEkApbldzrX5pKnBeH06dPk5OQwOjq6bsW1urqapqYmbH3Qylfv379nYGCA/v5+otEoABUVFRw6dMjnZB5KJqGnB7q6YG7OvE4mIS/PXGVlcOECtLaa1z5xay559sjw7t07Hj58SHt7+4bbL1YWVN6tLBgMEgwGuXv3Lh8+fPA7jveWlqChAc6dg6kpWF6GRMLcLSQS5vXUlGmPRk1/H7g5lzwrCK9evcK2bfbv37/u/V27djk/iKdOnfIqjqSRm5vLrVu36O3tpaSkhEgkwvnz53n69Knf0dyXTEJjI4yMQDyeuW88bh4ljh0z4zzm5lzyfZdhYGCA8fFx6urqtuZvpSzT3NzMzMwM9+7do7GxkcHBQcLhMJ2dnX5Hc1dPD78MD1O9ssLNNM1JoAmoB6YBVlZgbAxupuvtj68xlzwrCKFQCMuyePny5br39+zZQygUoqCgwKso8hn5+fkcOXKEjo4OBgcHaW1t5fLlyyQSCb+jucO2oauL3xIJxoBf03SZAKqAnz5tj8fNWoPHa19uziXPCkJpaSlHjx7l+vXr2l78nzlw4ACrq6ub9w5uaAjm5vgeOAj8kKZLDfAH0JHaPjtrxnvIzbnk6SPDjRs3WFtbo7a2lr6+Pl68eMHk5CR9fX1MTEywbds2L+NIioWFBRoaGujt7eX58+dMTU1x584durq6iEajFBcX+x3RHcPDkExyAjPpf0zTZTvwOzAEVH7asLpq1h085tZc8nTbsbKykmfPnnH16lUuXbrEmzdvyMvLo6qqira2Ns6cOeNlHEkRDAYJh8PEYjFev37NysoKO3fupKWlhYsXL/odzz2Li1++OJhImPEec2sueVoQAHbs2EEsFiMWi3n9reUzAoEAnZ2dm38BMVVRkTlT8CVrJNu3m/E+cGMu+b7LIOK7urp/HDL6Gfju4zWTaWxuLmyig1sqCCKRiDmB+Il2YPzj9W2mseXlZvwmoYIgYlnmOPJ/3a4rKDDjNtEJWxUEETCfTTh4EAKBf9c/EIDaWjh+3N1cHlNBEAGzhvDggVlP+NydQkGB6Xf/vq8fcHKDCoLI34JBePQIuruhshIKC82dgGWZr4WF5v3ubtMvGPQ78Vfn+bajSFbLy4OTJ+HECXMCcWRk/d9DCIc31ZpBKhUEkXQsC+rrzbWF6JFBRBwqCCLiUEEQEYcKgog4rEx/jNGyrHngT+/iiIgHKuwN/pVbxoIgIluLHhlExKGCICIOFQQRcaggiIhDBUFEHH8B7THOg20/kucAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x36 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy evaluation stopped @ iteration 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 1., 1., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Policy_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8c29f1",
   "metadata": {},
   "source": [
    "As we can see, the values for the default deterministic policy that always move the agent to the right produce a set of state values of 1 for the non-terminal states 1:5. This is what we expect since the accumulated return of this policy, given that γ=1, is 1 for these states since the agent is rewarded with 1 only when it reaches the far right terminal state, while when it is terminated at the far left state, it is rewarded with 0 (all other intermediate states also has a reward of 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aac185b",
   "metadata": {},
   "source": [
    "To further test our policy evaluation method, we will pass a different policy to it. This time we pass a simple probabilistic policy that gives left and right actions the same probability of 0.5. In this case, since γ=1, the expected analytical values of the intermediate states are given as 1/6, 2/6, 3/6, 4/6, 5/6, which represent the probabilities of ending up in the far right state given the agent has started in them (so pr(s=1)=1/6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a78d74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAApCAYAAADTTVdWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAFJElEQVR4nO3dX0hUaRzG8e8xbURHEWQ1tsCSqTBEliSZsTuHArva1Tsvc+mPdhNFVyUtgYEXwlDb1RoRghexy1JQhESEoOQf0mAjLNAlENSMQB1yRjx78baHnB2n3eicM6vPBw4y874vPhe+P89533fUsm0bERGAHL8DiEj2UEEQEYcKgog4VBBExKGCICIOFQQRceRmaiwpKbFDoZBXWTJaXl6msLDQ7xiObMqjLOkpS3pjY2Nvbdv+Jm2jbdsbXvv27bOzxePHj/2OsE425VGW9JQlPWDU3mDO65FBRBwqCCLi8LwgzM7OcvbsWfbu3Ut+fj5lZWXU19dz7do1lpaWvI4jKebn52lra2P37t0EAgHKy8uJRqP09/f7HU1SuDGXMi4qfm3T09McPnyY4uJirly5Qk1NDWtra0xOTnL79m1KS0tpaWnxMpKkaG5uJh6P09PTQygUYm5ujidPnrCwsOB3NG/ZNgwNwfAwLC5CURHU1UEkApbldzrX5pKnBeH06dPk5OQwOjq6bsW1urqapqYmbH3Qylfv379nYGCA/v5+otEoABUVFRw6dMjnZB5KJqGnB7q6YG7OvE4mIS/PXGVlcOECtLaa1z5xay559sjw7t07Hj58SHt7+4bbL1YWVN6tLBgMEgwGuXv3Lh8+fPA7jveWlqChAc6dg6kpWF6GRMLcLSQS5vXUlGmPRk1/H7g5lzwrCK9evcK2bfbv37/u/V27djk/iKdOnfIqjqSRm5vLrVu36O3tpaSkhEgkwvnz53n69Knf0dyXTEJjI4yMQDyeuW88bh4ljh0z4zzm5lzyfZdhYGCA8fFx6urqtuZvpSzT3NzMzMwM9+7do7GxkcHBQcLhMJ2dnX5Hc1dPD78MD1O9ssLNNM1JoAmoB6YBVlZgbAxupuvtj68xlzwrCKFQCMuyePny5br39+zZQygUoqCgwKso8hn5+fkcOXKEjo4OBgcHaW1t5fLlyyQSCb+jucO2oauL3xIJxoBf03SZAKqAnz5tj8fNWoPHa19uziXPCkJpaSlHjx7l+vXr2l78nzlw4ACrq6ub9w5uaAjm5vgeOAj8kKZLDfAH0JHaPjtrxnvIzbnk6SPDjRs3WFtbo7a2lr6+Pl68eMHk5CR9fX1MTEywbds2L+NIioWFBRoaGujt7eX58+dMTU1x584durq6iEajFBcX+x3RHcPDkExyAjPpf0zTZTvwOzAEVH7asLpq1h085tZc8nTbsbKykmfPnnH16lUuXbrEmzdvyMvLo6qqira2Ns6cOeNlHEkRDAYJh8PEYjFev37NysoKO3fupKWlhYsXL/odzz2Li1++OJhImPEec2sueVoQAHbs2EEsFiMWi3n9reUzAoEAnZ2dm38BMVVRkTlT8CVrJNu3m/E+cGMu+b7LIOK7urp/HDL6Gfju4zWTaWxuLmyig1sqCCKRiDmB+Il2YPzj9W2mseXlZvwmoYIgYlnmOPJ/3a4rKDDjNtEJWxUEETCfTTh4EAKBf9c/EIDaWjh+3N1cHlNBEAGzhvDggVlP+NydQkGB6Xf/vq8fcHKDCoLI34JBePQIuruhshIKC82dgGWZr4WF5v3ubtMvGPQ78Vfn+bajSFbLy4OTJ+HECXMCcWRk/d9DCIc31ZpBKhUEkXQsC+rrzbWF6JFBRBwqCCLiUEEQEYcKgog4rEx/jNGyrHngT+/iiIgHKuwN/pVbxoIgIluLHhlExKGCICIOFQQRcaggiIhDBUFEHH8B7THOg20/kucAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x36 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy evaluation stopped @ iteration 20:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.16481679, 0.33055852, 0.49722519, 0.66458556,\n",
       "       0.83229278, 0.        ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = randwalk()\n",
    "π = np.ones((env.nS,env.nA))*.5 # probability of moving left and right are equal\n",
    "Policy_evaluation(env, π)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "132fdb04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16666667, 0.33333333, 0.5       , 0.66666667, 0.83333333])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1/6, 2/6, 3/6, 4/6, 5/6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e871807a",
   "metadata": {},
   "source": [
    "As we can see the values of this optimal policy (moving always right) progressively increase from left to right towards the goal that is most rewarding and the obtained values are exactly what we expected which is reassuring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4796c21b",
   "metadata": {},
   "source": [
    "Let us try to evaluate a random policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f19cd40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "env = randwalk()\n",
    "π = np.random.randint(env.nA, size=env.nS, dtype=np.uint32)\n",
    "print(π)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71b0b9d",
   "metadata": {},
   "source": [
    "Now we call our policy evaluaiton subroutine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdc781d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAApCAYAAADTTVdWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAFJElEQVR4nO3dX0hUaRzG8e8xbURHEWQ1tsCSqTBEliSZsTuHArva1Tsvc+mPdhNFVyUtgYEXwlDb1RoRghexy1JQhESEoOQf0mAjLNAlENSMQB1yRjx78baHnB2n3eicM6vPBw4y874vPhe+P89533fUsm0bERGAHL8DiEj2UEEQEYcKgog4VBBExKGCICIOFQQRceRmaiwpKbFDoZBXWTJaXl6msLDQ7xiObMqjLOkpS3pjY2Nvbdv+Jm2jbdsbXvv27bOzxePHj/2OsE425VGW9JQlPWDU3mDO65FBRBwqCCLi8LwgzM7OcvbsWfbu3Ut+fj5lZWXU19dz7do1lpaWvI4jKebn52lra2P37t0EAgHKy8uJRqP09/f7HU1SuDGXMi4qfm3T09McPnyY4uJirly5Qk1NDWtra0xOTnL79m1KS0tpaWnxMpKkaG5uJh6P09PTQygUYm5ujidPnrCwsOB3NG/ZNgwNwfAwLC5CURHU1UEkApbldzrX5pKnBeH06dPk5OQwOjq6bsW1urqapqYmbH3Qylfv379nYGCA/v5+otEoABUVFRw6dMjnZB5KJqGnB7q6YG7OvE4mIS/PXGVlcOECtLaa1z5xay559sjw7t07Hj58SHt7+4bbL1YWVN6tLBgMEgwGuXv3Lh8+fPA7jveWlqChAc6dg6kpWF6GRMLcLSQS5vXUlGmPRk1/H7g5lzwrCK9evcK2bfbv37/u/V27djk/iKdOnfIqjqSRm5vLrVu36O3tpaSkhEgkwvnz53n69Knf0dyXTEJjI4yMQDyeuW88bh4ljh0z4zzm5lzyfZdhYGCA8fFx6urqtuZvpSzT3NzMzMwM9+7do7GxkcHBQcLhMJ2dnX5Hc1dPD78MD1O9ssLNNM1JoAmoB6YBVlZgbAxupuvtj68xlzwrCKFQCMuyePny5br39+zZQygUoqCgwKso8hn5+fkcOXKEjo4OBgcHaW1t5fLlyyQSCb+jucO2oauL3xIJxoBf03SZAKqAnz5tj8fNWoPHa19uziXPCkJpaSlHjx7l+vXr2l78nzlw4ACrq6ub9w5uaAjm5vgeOAj8kKZLDfAH0JHaPjtrxnvIzbnk6SPDjRs3WFtbo7a2lr6+Pl68eMHk5CR9fX1MTEywbds2L+NIioWFBRoaGujt7eX58+dMTU1x584durq6iEajFBcX+x3RHcPDkExyAjPpf0zTZTvwOzAEVH7asLpq1h085tZc8nTbsbKykmfPnnH16lUuXbrEmzdvyMvLo6qqira2Ns6cOeNlHEkRDAYJh8PEYjFev37NysoKO3fupKWlhYsXL/odzz2Li1++OJhImPEec2sueVoQAHbs2EEsFiMWi3n9reUzAoEAnZ2dm38BMVVRkTlT8CVrJNu3m/E+cGMu+b7LIOK7urp/HDL6Gfju4zWTaWxuLmyig1sqCCKRiDmB+Il2YPzj9W2mseXlZvwmoYIgYlnmOPJ/3a4rKDDjNtEJWxUEETCfTTh4EAKBf9c/EIDaWjh+3N1cHlNBEAGzhvDggVlP+NydQkGB6Xf/vq8fcHKDCoLI34JBePQIuruhshIKC82dgGWZr4WF5v3ubtMvGPQ78Vfn+bajSFbLy4OTJ+HECXMCcWRk/d9DCIc31ZpBKhUEkXQsC+rrzbWF6JFBRBwqCCLiUEEQEYcKgog4rEx/jNGyrHngT+/iiIgHKuwN/pVbxoIgIluLHhlExKGCICIOFQQRcaggiIhDBUFEHH8B7THOg20/kucAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x36 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy evaluation stopped @ iteration 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.01, 0.01, 0.01, 1.  , 1.  , 0.  ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Policy_evaluation(env, π)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5b213b",
   "metadata": {},
   "source": [
    "As we can see the set of values are different than the above optimal policy and they are in harmony with the policy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bec294b",
   "metadata": {},
   "source": [
    "### Policy Evaluation for Grid world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ba884b",
   "metadata": {},
   "source": [
    "Let us now try this on a slightly more complex env such as a grid world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a54887af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:11<00:00, 11.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy evaluation stopped @ iteration 7:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "env = maze()\n",
    "π = np.ones(env.nS, dtype=np.uint32)*3 # always go up\n",
    "V = Policy_evaluation(env=env, π=π)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b730964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.render(underhood='V', V=V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368d34bd",
   "metadata": {},
   "source": [
    "As we can see moving up yeild some benefits mainly in the cells that lead to the goal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a79ff17",
   "metadata": {},
   "source": [
    "Let us now generate a random policy and evaluate it for a maze environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ee3a392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 0 0 1 0 3 1 0 2 1 2 0 2 1 2 0 3 0 2 0 1 2 2 0 3 3 1 1 3 2 0 2 1 1 1 3\n",
      " 3 1 2 1 1 0 0 1 0 0 1 3 3 2 1 0 2]\n"
     ]
    }
   ],
   "source": [
    "env = maze()\n",
    "π = np.random.randint(env.nA, size=env.nS, dtype=np.uint32)\n",
    "print(π)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2f58faf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.render(underhood='π', π=π)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "830b5e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:11<00:00, 11.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy evaluation stopped @ iteration 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.  , 0.  , 0.01, 0.01, 0.01,\n",
       "       0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.01, 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Policy_evaluation(env, π)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7ff08e",
   "metadata": {},
   "source": [
    "As we can see, the randomly generated policy is chaotic and carry little value for the agent. However, evaluating different policies is highly important for an agent since it can guide the improvement of its adopted policy (based on this ability). One example is to keep evaluating random policies until some computational resources are consumed and pick the best. Below we show such a strategy of searching for an optimal policy. You can apply all other search algorithms that you have come across before in conventional AI (breadth-first etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bc4235e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:11<00:00, 11.81s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "env = maze()\n",
    "Vmax= np.zeros((env.nS))\n",
    "p = dynamics(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8c38af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASUAAACxCAYAAACC56uWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAX1ElEQVR4nO3de3QU5d3A8e+GkIRACBoFDSJi4luzBJQAMSggNVwak2itYD3ai4haC+3xeKn2aKl4AY/UorQvVOvL21rAltP2rRIuKiJ3IreAhwWkWLVcwiUghGAIJGTePx62m3vY2Zl5dmZ/n3PmwMzuzu95npn8dmZ25nl8hmEghBDRIk53AYQQoiFJSkKIqCJJSQgRVSQpCSGiiiQlIURUkaQkhIgq8W29eNFFFxnp6elOlUUIESN27tx51DCMS1t6rc2klJ6ezo4dO+wpVTsCgQDZ2dkSW2J7PvbOnTu1xPb7/drq7fP5/t3aa3L6JoSIKpKUhBBRRZKSECIigUCAnJwcEhIS8Pl8xMXFkZKSwtixYzl06FDY62vzmpIQQjRiGFBaChs3QlUVaysquHnWLOLj43n44YcZOXIk586do7S0lLlz5/LCCy8wa9assEJIUhJCtK+2FubMgenT4cgRNV9byx2GgQ/Y16MH3f1+KCiAjh254447mD59OvX19WGHkqQkhGjbqVMq2ZSVQXX1fxb/CzgKjAG679sHjz8Ob78NS5ZAly4AxMWFf4VIrikJIVpXW6sS0qZNjRISwMrz/14XXFBdDRs30iElBZ/Ph8/nw+/3hx1SkpIQonVz5kBZGf9z5gzZwP+28JZzwHeAG4Evz5xhRUICHz7yCN26dePs2bNhh3RlUjIM+OQTePFF+Mc/JHa0qqyESZNg4cJmX7Ke5pl6G4a6hlRdzf8BW4C/N3h5+Pl/1wJZwHPnXx9+9iz5JSUkJCSYCuuaa0o1NbBiBZSUwKJFsG8fpKbCl19K7GiVmgp1dXD77ZCUBPn5UFwMRUXQs6fu0tnHM/UuLVUXtYFvAznAow1evgZIAzYC3YCPgPnBFw8fBi8mpUOHYPFi9ce4bBl8/XXj1zt2hLFjm38uL08dTUhs55SWwuTJzZcfPar+ralRdVq8WM0PGKD+UIuLISfHuXJazdP13rhRXVMCHjo/NfU3IB+VkH4EBIA9wKLTpzlWXU3qJZeEHdaWpLR6Nfz615CdDVOnmlvHzp1JzJ8PH3ygNmxLjh6F5cubL+/UyVzMWI8didbK1JqtW9X0zjvw0ENw003m4lqxr0VCV70dUVX1n6TUmhHAVuAHwOvAf59fnlxfT35GBn9YuTLssLYkpQMH1Pn0yZPm1+H31/Duu+qcfPny0OnLwYOh92RkwHPPNf9spIfIsRo7EgMGwLx5zZevWgVvvhmaT0iAb34zdDrTu7daHgiYi2vFvhYJXfV2REqKOixv52J1f2Bb04WJifDTn4KJXkai+vQNIDk5dLhbX6++ZUpK1LR1K/j9aseQ2HpdcQXce2/jZYYBM2fCpZdCYaGqy6hRal/3Ck/XOze3xaQ0Cwjm2yVAi2knPh4GDzYVNuqTUkNxcTBwoJqmTFHfksFzd4kdfU6ehN/8Ru2bHTroLo1zPFPvIUOge3f44otGiyedn9rUo4f6vAmuvCUgqGdPuO669t8nsfVITVUX3139h2mCZ+rt88GTT6rD9nAkJ6vP+XymwlqalLZvh23bGi87eRLefdfKKELIvuaYCRPUz4SJiRf2/sREdUh///2mQ1qalNLSVPmffVbNBwJw1VXqhj8hrCT7mkM6doSlS9X1pfaOmJKT1fuWLFGfM8nSpJSernaUPXvU/NGjcPy4+rVBCCvJvuagLl3UT8EzZsDVV0PnzuqIyOdT/3burJbPmKHed/5hXLMsv9BdXAxbtoTme/aMrl+JhHfIvuagjh3hRz9SN1eVlqoHdKuq1E+KubnqIprJa0hN2ZKUpkwJzRcVWVZWIRqRfU0Dnw9uvFFNNrH817cBAxrfL1VcbHUEIRTZ17zJ8qTk84XO6zt1gltusTqCEIrsa/oYhn3rtuU+peA31qhRep/HEt4n+5oeJSX2rduWpJSfr3YQOZwWdsvPV3e8m3yiQZj0yiuwe7c96273QnfA5BODN9xwJRkZ5QQCdaY+H0lsK0hsd8Q+caID9fXXsn//EQKBCkdjW8VMl7FWMdvm69Zdy5tvHuK++45ZXqZ2k5LZYX1feQUGDuxq6rMgQynroLvNzcSef75XsV27epCd3cPR2FZw4742f756SHzTpst55ZXLLS+Xbc++DRxo15qFCAle21i3Dr76Sm9ZYoXdbe7qB3JFbKuthffeU/8/dy70f2EfJ9pckpJwrTVrVCf9QXb+IiQUJ9pckpJwrUWLGs8vXdpu760iQk60uSQl4UqG0fxburIS1q7VU55Y4FSbS1ISrrR7Nxw7BmPGqPk+feCGG+QUzk5OtbkkJeFKnTqpse9++EM137u3enh9/HitxfI0p9rcVX10CxEUHA2kIZ8P+vVzviyxwqk2d/RIqbISZs2yZnTX6mo1tE44Y27FImlz51nZ5rHI0aSUmqpGfO3TR2XXp59Wh3/nzl3Y5/fvhzfeUE+Gp6WpUWKvucbeMrudtLnzIm3zWGfb6duOHTBnTvPldecfhQsE1PTSS2p8rFtvVQ/wjh4dGh+rvh7KyhqPd9ZQr17w2mvNY/j98MADllbHFaTNnWdFm4vGbEtKn38Or756Ye+tqIC33lJTaiq8+CKkpSXx4IPw8cetf27fvpZjFBXF5h9ILLZ5v37w/PMtX+9wQqRtPnSoveWzg91tbltSyshQQz819emn6rpEQ+npaqcuLlYddSUnQyBQw/r1aiid4NDVGzY07lzqyivh7rubx8jKsrYubhGLbZ6drSZdIm9zZ8ppJbvb3Lak5PfDyy83Xx7sYyknJzQsdU5Oy30r+3zQv7+annkGDh9Wo7eUlMAHH0B5OUycqO9bMtpImzvPijYXjTl6S0BlJdx2G7z+uhp5Ilw9eqh7IsaPh5oaWLlSHT7LH0jrpM2dF2mbxzpHk1JqKjz4oDXrSkqCb33LmnV5mbS586xs81gkd3QLIaKKJCUhRFSRpCSEiCqSlIQQUUWSkhAiqkhSEkJEFUlKQoioYltS2rTJrjWL1uhs81jd3lJv69mWlJ5/Xj2SIJyjs81jdXtLva3nMxo+bdlE3759jQULFoS90tOnfQwblsVTTx1k3LjjkZRPXCCdbR6r21vqbb7e/fr122IYxqCWXrNl2O6SEjhzBsrKevLcc+Ye/pGhlMOjs829sL111jsW97W22HL6Fhzd4MMPVReqwn462zxWt7fU2556W56U6utDA9bV1MBHH1kdQTSls81jdXtLve2rt+VJqawMDh4MzZeUQEVFBRMnTuSqq64iMTGRHj16kJ+fz7Jly6wOH5NaavNYiK2T1Fuxo96Wd13SdFjfRYtg1647qa6uZs6cOWRmZnLkyBFWrVrFsWPHrA4fk1pqc8NwpkMxnbF1knqH5q2ut+VJqWnmLC8/QXn5GpYtW0Z+fj4AvXv3ZvDgwVaHjlnN21x9ow0c6O3YOkm9FTvqbenp24EDsG1bqL/mSy+FtLQuJCR0YeHChdTU1FgZTtBym19yiTOnEzpj6yT1VvN21dvSpHT8OHzyCUyerOb79oUvv4znscf+yLx58+jWrRtDhgzhiSeeYMOGDVaGjlkttfkXX8CgFu8A8U5snaTeat6uelualFoa5aBLF3jppTspLy+npKSEgoIC1q9fT15eHtOmTbMyfExqrc2LirwdWyepd4gd9XbsgdykpCRGjRrFL3/5S9avX8+ECROYMmUKZ8+edaoIIoZUVsLq1aFBIYV7aOslwO/3U1dXJ9eZhC26doWnnoLu3eF734O//AVOnNBdKnEhbB/N5NixY4wbN47777+f/v37k5KSwubNm5k+fTr5+fl07drV7iIIj9u3D5Yvb768b1812u/8+WqKj4dhw0LjsGVmOl9W0T5bklKvXnDnnWqn6NKlC3l5ecycOZPPPvuMM2fO0LNnT+655x5+8YtfWB57717YuFH9MnDzzZavPmo1bPNYig3qF6Hx49t/X10drFihpsceg2uvhUmTzA+drbveuthdb1uS0tChDTd0ItOmTXPsova6dXDPPTBihNr5YkXjNo+d2KC+gFoaj66iArZsabzM54Pc3NDRUr9+sGOHubi6662L3fV2dDBKIeyQlwdLlzZf/sADKil17gyjR6skdOutatRfEb0kKQlPqqyElBSVrEaMUKP7CneQpCQ8KTUVXn1VdymEGZ4ZOOCrr1S3Ck3JM79CuItnktLnn8P110OwN5SKCrjvvtAt8UIId/DM6VtODhw9Cn/4g5rfsUNNCxfqLZcQIjyeOVKKi4PCwsbLkpLgfG8pQgiX8ExSAvWTb0P5+ZCcrKcsQghzPJWURo5s/NNv0yQlhIh+nkpKycmNT9e83pWEEF7kqaQEoUSUkwM9rR+SSohGvvhCdwm8x7NJSU7dhBOmTJEuUaxmy7Ddut11VwbPPnuAvn2lryZhn9pauPnmLCZPLqegoFJ3cVzF8WG7rRDJMM6PPALjxmUSZ/I40I1DKVvBjUNn64y9ciVUVcG2bb342c96ORrbCjpjt8Vzp2+gng43m5CEuFDBMdCWLpVud63kyT/dDh10l0DEguDQQsePq368hDU8mZSEsNs//6mmoKYjxwrzJCkJYULTARi9PhClkyQpCWFC0yOj3bthzx49ZfEaSUpChOn4cVizRvVsCepJgrg4OVqyiiQlIcK0Z48asmn2bDWfm6u6yZGHv63hmf6UhHBKbq6a/vzn0LJrr1WTiJwcKXncqVP6ugTWGTtWeaHN5UjJ45KSYNAgNTZaUZF6JjArS41/5uXYscoLbS5JyUNOnFB9lTf17W/Dyy/D2rXw85/D1VeHBmMcNgwSEtwdO1Z5tc1tSUonT8KhQ9Cpkxri10k6Y+u2Zg3cdlv77/v8c5g5U01du6rRZW+/Hfx+98XWub1TUuCaa+CKK5yNG+TVNrflmtLixfCNb8APfmDH2qM3tm5JSZCe3nxKS2v5/cEdtLgYxoyB+Ai+onTF1rm9i4rUXd1z5zofG7zb5nL65iGjRsGBA82XP/MMTJum/p+RETqUHzq08aH8wYPujB2rvNrmkpQ8rrIStm1T1xiKi9XP1k5d9NQZO1Z5oc0lKXlcaqo63I612LHKC21u6TWlc+fCW+6V2MJ5sr2d51SbW5qU1q6Fe+9VDycCnD4NM2bA449bGSX6YgvnyfZ2nlNtbunp2403qp8aK893V7xhg5rmzbMySvTFFs6T7e08p9rc0iOljh3VT44NdegABQVWRom+2MJ5sr2d51SbW36fUtMBIG+6CS6+2Ooo0RdbOE+2t/OcaHPLk1JBQeNO+50cf01nbOE82d7Oc6LNLU9KaWkqewY5OXS2ztjCebK9nedEm9vymEkwe2ZmqtvRnaQztm7Hj+sugfN0b29pc+vXb0tSCmbPggLn7yZtOGy32+5kjdSLL6qfaWOJ7u0tbW79+tu9JSAQCIS90vp66NChL3FxhwkEjpoqmNnYhgG9el1DdnY5gcDXpmP7I3lkPkJm6z1v3jfIyDjA8OGnHI1tFZ3bW9r8wlnV5q2xZdjusjJ1l2d19WVkZ19mqmCRDCn8wAPw/e/3oWNHUx935VDKZWVw5Ahs334VEyc6G9sKkQyVnpcHSUm72LnTMPV5s0Ole6HNdf2NtcWW07fgqA5Ll6qs6rQnnsCWxopmwTZftEhPm+tUXLyb+HjnKx3LbW7n35gtSSk4Jtb+/eqJZafF4qgSuttcp8REPQ+8xXKb2/k3ZnlSKi+HzZtD8zIWlv2kzZ0nbW4fy5NS024TZGPZT9rcedLm9rE8KTXdOJs3R28Pd14hbe48aXP7WJqUTp+GDz9svtztnU5FM2lz50mb28vSpLR5Mzz6KPz2t2p++HD4+99h714ro4iGpM2dJ21uL0v7Uxo2TE3B4Yzj4uA731GTsIe0ufOkze0lw3ZHoLZWdwn0iNV6u0FdnfX3TDm9vSUphcEwYOdONVLE0KHwt7/pLpEzYrXebnTmDAweDJMmwXvvQU1N+OvQvb1lNJN2nD0Lq1erG+VKSkLDJGdmwh13qG+mhnw+1Ruf28Vqvd2kvl5NDSUmwp13wtNPw+zZ0LmzGh+uuBgKC6FHj5bXFU3bW5JSC06c6MDcuWrjvP++Gqa4qc8+U8MWN1VU5N57VmK13m61eHH7w3Z//TW8846afD7IzVUJqqgITp6Mzu1ty+nbXXepn03ff9+OtbdtwQI1nPHo0ebXUV0dR2Wl6iDdzOGvDla0uRvrrZPO/dwMw+A/2/fkSTh1Kjq3ty1HSh066DuUr69X59WRXJxLT69l9Gj4yU+gqgqWLVPfCosXQ0WFek9mJqxb17hrUGg8LLKTrGhzN9ZbJ537Oagv3uB2aWj2bHj2WfX/+Hh1y0Lw6CgzM/S+QKCWgoLo295y+taOlJTQz7319bBxo9pwJSXqHHzsWN0ltEes1ttNEhPV1NDp0/DXv6rx2YqLYcwY6Nat/XVF0/aWpBSGuDjVd09eHkydqs7XY0Gs1tuN4uJg61Z1hBTJOnRub0lKEejcWXcJ9IjVertB0yMnKzi9vT1zn9Lateq+ilPneyU1DPV80tSpesslhAiPZ46UBgyAkSNDF7jXrFH3Z8yerbdcQojweOZIqXNnuOWW0M1kwX9lLDAh3MUzSQmaj9Z5/fXQq5eWogghTPJUUiosbDwvwzgL4T6eSkpXXgnXXReal6QkhPt4KilBKBFddhkMHOh8/DNnnI8phJd4NikVFja/Nd4Jr73W/IlqIcSF81xSGjRIdc+g69Ttj3+Ejz/WE1sIL/AZbXRT17dvX2PBggUOFscaU6dezqOPHiI52dlhS/fuTaCw8L8YP76Cxx477GhsIdykX79+WwzDGNTii4ZhtDr5/X5Dl+3bt5v+7OHDemLPmGEYYBhZWc7HtoLElthOATYbreQdz52+AXTvriducBjnXbvgX//SUwYh3M6TSUmHykrVxUOQ9MIohDmSlCzy3nuNf3WTpCSEOZKULNI0Ca1erY6ehBDhkaRkgbo6WLKk+TK39N0sRDSRpGSB0lK46SZ48kk1P3Cg6iN5zRq95RLCjTzTn5JOubnq9C04jHNKCkyZIo+cCGGGHClZoLUuSO3omlQIrzOdlGpqYOlSmDhRjbXmJJ2x3aayEr77XXjjDdi/3/x6ZHtfOKva3G0qK9VYeK+/Hlm9wzp9O3RIXdAtKVFjRH39tbpR8Ve/Ml8AN8R2s9RU1dHdww+r+QED1HOBxcWQk9P2Q8uyvc2JpM3dLDVVdR/04x+ryWy9201Kn3wSGv9p48bmr58+DYMHN18+YkRk/WMbhr7YbrViBUya1Hx5wyFytm5V0/PPw+WXq+6Ci4shP19vm7t1e0fa5m5lpt6FhareI0e2ve42k1JNTRyzZqnHJw4ebPk9VVXqsYqmMjLaDtyeTz9NYtkyPbHNGj0aNmxQF7p1OHWq5fZozcGD8NZbsHevGhE1OTmJjz6S7R2OSNs8J8dc3Pffh8mT1S+9v/uduXVEwky9//Qn2LcPjh5t+71tJqWkpHp+/3vVCf/WraFvsbKy0HsyM9W5c1NpaRde4JZkZdUwbpye2GalpemLDTBkCCxf3nx5SYnq5ymoe3f1rVVUpEZ8CSbRQKCGu++W7R2OyNvcXNyvvoJNm/SNwRdpvSdMaGPlrT2pa7TRS8D+/YbxxhuGUVRkGElJhrFqlfVPEbf2BLPO2E6wOnZdnWH4/YbRv79hPP20YZSWGsa5c+HFlu0dHivavD1vv616pBgxwnw5ddabNnoJMHWfUs+e8NBDaqqubv1w2w46Y7tRdbW6YNy7t/l1yPYOjxVt7kZW1TvimyeTk/Wd0+uM7RYpKdZe45Lt3T6r29wtrKq3R3+cFMKbtmxR92w17DB23z7VDbNXyGMmQrhI797qsaaLL1bzW7aoo8cXXtBbLivJkZIQLnLJJeqXr+DP6lVVUFvrrTEOJSkJ4TJNE9DVV0NWlp6y2EGSkhAu0zQpFReDz6enLHaQpCSEy2RlQZ8+ofmiIn1lsYMkJSFcxucLHS117QrDh+stj9UkKQnhQsGkNGYMJCToLYvVJCkJ4ULDh6ujJC/96hbU5rDdPp+vAvi3c8URQsSI3oZhXNrSC20mJSGEcJqcvgkhoookJSFEVJGkJISIKpKUhBBRRZKSECKq/D9sc+X3BRKz+gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1224x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for _ in trange(200):\n",
    "    π = np.random.randint(env.nA, size=env.nS, dtype=np.uint32)\n",
    "    V = Policy_evaluation(env, π, p, False)\n",
    "    if Vmax.sum() < V.sum(): \n",
    "        Vmax = V\n",
    "        πmax = π\n",
    "\n",
    "env.render(underhood='π', π=πmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56d3677",
   "metadata": {},
   "source": [
    "As we can see, finding the optimal policy by random search is difficult since the space of policies is huge, making exhaustive or random search infeasible (dimensionality problem). We need a way to take and maintain a step in the right direction of improving the policy. As you have already seen in another module, a greedy search can often lead to a good result. The next section shows a simple but effective strategy to gradually improve a policy by taking a greedy step towards the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64da4ba2",
   "metadata": {},
   "source": [
    "## Policy Iteration \n",
    "Now that we know how to evaluate a policy, it is time to improve it. Policy iteration is a basic and simple algorithm. It explicitly and iteratively tries first to reach a highly accurate estimate of the value function of the current policy, then it tries to improve the policy by maximising the probability of greedy actions as per the current value function. Evaluating the current policy fully and then improving it via policy iteration is inefficient, but it shows the fundamental ideas behind reinforcement learning. Please spend some time comprehending the code and reading the corresponding section 4.3 in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87d9afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1) # change the seed to get a different dynamics\n",
    "\n",
    "def Policy_iteration(env=randwalk(), v0=.01, θ=1e-4, γ=.99, isrand=False): \n",
    "    nS, nA, nR = env.nS, env.nA, env.nR\n",
    "    \n",
    "    # m states, k actions and d rewards returns a 4-d dynamics\n",
    "    if isrand: p = dynrand(nS, nA, nR); rewards = [-1,1] \n",
    "    else:      p = dynamics(env);       rewards = env.rewards_set() # obtain a model of the env\n",
    "        \n",
    "    # 1. initialise arbitrarily -------------------------------------------------\n",
    "    V  = np.ones (nS )*v0; V[env.goals] = 0 \n",
    "    π  = np.zeros(nS, dtype=np.uint32) # policy for all states\n",
    "    Qs = np.zeros(nA) # action-values for individual state\n",
    "     \n",
    "    j=0\n",
    "    while True:\n",
    "        j+=1\n",
    "        # 2. policy evaluation---------------------------------------------------\n",
    "        i=0\n",
    "        while True:\n",
    "            Δ = 0\n",
    "            i+= 1\n",
    "            for s in range(nS):\n",
    "                v, V[s] = V[s], 0\n",
    "                for sn in range(nS):\n",
    "                    for rn, r in enumerate(rewards):\n",
    "                        V[s] += p[sn,rn,  s, π[s]]*(r + γ*V[sn])\n",
    "                Δ = max(Δ, abs(v-V[s]))\n",
    "            if Δ<θ: print('policy evaluation stopped @ iteration %d:'%i); break\n",
    "\n",
    "        # 3. policy improvement----------------------------------------------------\n",
    "        policy_stable=True\n",
    "        for s in range(nS):\n",
    "            πs = π[s]\n",
    "            for a in range(nA):\n",
    "                Qs[a]=0\n",
    "                for sn in range(nS):\n",
    "                    for rn, r in enumerate(rewards):\n",
    "                        Qs[a] += p[sn,rn,  s,a]*(r + γ*V[sn]) \n",
    "            π[s] = Qs.argmax() # greedy step\n",
    "            if π[s]!=πs: policy_stable=False\n",
    "        if policy_stable: print('policy improvement stopped @ iteration %d:'%j); break\n",
    "    return π"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a153808",
   "metadata": {},
   "source": [
    "We try our policy_iteration() funciton for a random dynamcis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41f3e392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy evaluation stopped @ iteration 6:\n",
      "policy evaluation stopped @ iteration 6:\n",
      "policy improvement stopped @ iteration 2:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0], dtype=uint32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Policy_iteration(isrand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e80f9bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy evaluation stopped @ iteration 5:\n",
      "policy evaluation stopped @ iteration 5:\n",
      "policy improvement stopped @ iteration 2:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 1], dtype=uint32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Policy_iteration(isrand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee56795",
   "metadata": {},
   "source": [
    "We can of course try it for a proper Environments. We start by a random walk and then we move into grid world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59f54ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAApCAYAAADTTVdWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAFJElEQVR4nO3dX0hUaRzG8e8xbURHEWQ1tsCSqTBEliSZsTuHArva1Tsvc+mPdhNFVyUtgYEXwlDb1RoRghexy1JQhESEoOQf0mAjLNAlENSMQB1yRjx78baHnB2n3eicM6vPBw4y874vPhe+P89533fUsm0bERGAHL8DiEj2UEEQEYcKgog4VBBExKGCICIOFQQRceRmaiwpKbFDoZBXWTJaXl6msLDQ7xiObMqjLOkpS3pjY2Nvbdv+Jm2jbdsbXvv27bOzxePHj/2OsE425VGW9JQlPWDU3mDO65FBRBwqCCLi8LwgzM7OcvbsWfbu3Ut+fj5lZWXU19dz7do1lpaWvI4jKebn52lra2P37t0EAgHKy8uJRqP09/f7HU1SuDGXMi4qfm3T09McPnyY4uJirly5Qk1NDWtra0xOTnL79m1KS0tpaWnxMpKkaG5uJh6P09PTQygUYm5ujidPnrCwsOB3NG/ZNgwNwfAwLC5CURHU1UEkApbldzrX5pKnBeH06dPk5OQwOjq6bsW1urqapqYmbH3Qylfv379nYGCA/v5+otEoABUVFRw6dMjnZB5KJqGnB7q6YG7OvE4mIS/PXGVlcOECtLaa1z5xay559sjw7t07Hj58SHt7+4bbL1YWVN6tLBgMEgwGuXv3Lh8+fPA7jveWlqChAc6dg6kpWF6GRMLcLSQS5vXUlGmPRk1/H7g5lzwrCK9evcK2bfbv37/u/V27djk/iKdOnfIqjqSRm5vLrVu36O3tpaSkhEgkwvnz53n69Knf0dyXTEJjI4yMQDyeuW88bh4ljh0z4zzm5lzyfZdhYGCA8fFx6urqtuZvpSzT3NzMzMwM9+7do7GxkcHBQcLhMJ2dnX5Hc1dPD78MD1O9ssLNNM1JoAmoB6YBVlZgbAxupuvtj68xlzwrCKFQCMuyePny5br39+zZQygUoqCgwKso8hn5+fkcOXKEjo4OBgcHaW1t5fLlyyQSCb+jucO2oauL3xIJxoBf03SZAKqAnz5tj8fNWoPHa19uziXPCkJpaSlHjx7l+vXr2l78nzlw4ACrq6ub9w5uaAjm5vgeOAj8kKZLDfAH0JHaPjtrxnvIzbnk6SPDjRs3WFtbo7a2lr6+Pl68eMHk5CR9fX1MTEywbds2L+NIioWFBRoaGujt7eX58+dMTU1x584durq6iEajFBcX+x3RHcPDkExyAjPpf0zTZTvwOzAEVH7asLpq1h085tZc8nTbsbKykmfPnnH16lUuXbrEmzdvyMvLo6qqira2Ns6cOeNlHEkRDAYJh8PEYjFev37NysoKO3fupKWlhYsXL/odzz2Li1++OJhImPEec2sueVoQAHbs2EEsFiMWi3n9reUzAoEAnZ2dm38BMVVRkTlT8CVrJNu3m/E+cGMu+b7LIOK7urp/HDL6Gfju4zWTaWxuLmyig1sqCCKRiDmB+Il2YPzj9W2mseXlZvwmoYIgYlnmOPJ/3a4rKDDjNtEJWxUEETCfTTh4EAKBf9c/EIDaWjh+3N1cHlNBEAGzhvDggVlP+NydQkGB6Xf/vq8fcHKDCoLI34JBePQIuruhshIKC82dgGWZr4WF5v3ubtMvGPQ78Vfn+bajSFbLy4OTJ+HECXMCcWRk/d9DCIc31ZpBKhUEkXQsC+rrzbWF6JFBRBwqCCLiUEEQEYcKgog4rEx/jNGyrHngT+/iiIgHKuwN/pVbxoIgIluLHhlExKGCICIOFQQRcaggiIhDBUFEHH8B7THOg20/kucAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x36 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy evaluation stopped @ iteration 2:\n",
      "policy evaluation stopped @ iteration 2:\n",
      "policy evaluation stopped @ iteration 2:\n",
      "policy evaluation stopped @ iteration 2:\n",
      "policy evaluation stopped @ iteration 2:\n",
      "policy evaluation stopped @ iteration 2:\n",
      "policy improvement stopped @ iteration 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "env=randwalk()\n",
    "π = Policy_iteration(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858564eb",
   "metadata": {},
   "source": [
    "To visualise the policy we would need to pass the environment explicitly and then render the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "164c03cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(π)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "07724d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x36 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.render(underhood='π', π=π)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0baef785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x36 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.render(underhood='π', π=π)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3737d08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:11<00:00, 11.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy evaluation stopped @ iteration 2:\n",
      "policy evaluation stopped @ iteration 2:\n",
      "policy evaluation stopped @ iteration 2:\n",
      "policy evaluation stopped @ iteration 2:\n",
      "policy evaluation stopped @ iteration 2:\n",
      "policy evaluation stopped @ iteration 2:\n",
      "policy evaluation stopped @ iteration 2:\n",
      "policy evaluation stopped @ iteration 2:\n",
      "policy evaluation stopped @ iteration 2:\n",
      "policy evaluation stopped @ iteration 2:\n",
      "policy evaluation stopped @ iteration 2:\n",
      "policy evaluation stopped @ iteration 2:\n",
      "policy evaluation stopped @ iteration 2:\n",
      "policy evaluation stopped @ iteration 2:\n",
      "policy evaluation stopped @ iteration 2:\n",
      "policy evaluation stopped @ iteration 2:\n",
      "policy improvement stopped @ iteration 16:\n"
     ]
    }
   ],
   "source": [
    "env=maze()\n",
    "π = Policy_iteration(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f37ad22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.render(underhood='π', π=π)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac88ba30",
   "metadata": {},
   "source": [
    "## Stochastic Policy Iteration\n",
    "We can also create a stochastic policy iteration method. It only differs from the deterministic policy iteration in two places (in the if ε_greedy statements): \n",
    "1. in the policy evaluation, we need to marginalize by multiplying by the action probability as we did earlier for the policy evaluation method\n",
    "2. In calculating the probability of taking an optimal action (to account for the stochastic non-determinism nature of the policy), we allow the agent to take random actions ε% of the time. \n",
    "\n",
    "We show the method below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ffdabb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1) # change the seed to get a different dynamics\n",
    "\n",
    "def Policy_iteration_stoch(env=randwalk(), v0=.01, θ=1e-4, γ=.99, ε=.1, isrand=False): \n",
    "    nS, nA, nR = env.nS, env.nA, env.nR\n",
    "    \n",
    "    # m states, k actions and d rewards returns a 4-d dynamics\n",
    "    if isrand: p = dynrand(nS, nA, nR); rewards = [-1,3] \n",
    "    else:      p = dynamics(env);       rewards = env.rewards_set() # obtain a model of the env\n",
    "        \n",
    "    # 1. initialise arbitrarily -------------------------------------------------\n",
    "    V  = np.ones (nS )*v0; V[env.goals] = 0 \n",
    "    π  = np.ones((nS, nA)) # probabilistic policy\n",
    "    for s in range(nS): π[s] /= π[s].sum()\n",
    "    Q  = np.ones((nS, nA))  # action-values for individual state\n",
    "\n",
    "    j=0\n",
    "    while True:\n",
    "        j+=1\n",
    "        # 2. policy evaluation---------------------------------------------------\n",
    "        i=0\n",
    "        while True:\n",
    "            Δ = 0\n",
    "            i+= 1\n",
    "            for s in range(nS):\n",
    "                v, V[s] = V[s], 0\n",
    "                for sn in range(nS):\n",
    "                    for rn, r in enumerate(rewards):\n",
    "                        for a in range(nA): \n",
    "                            V[s] += π[s,a]*p[sn,rn, s,a ]*(r + γ*V[sn]) # probabilistic policy\n",
    "                        \n",
    "                Δ = max(Δ, abs(v-V[s]))\n",
    "            if Δ<θ: print('policy evaluation stopped @ iteration %d:'%i); break\n",
    "\n",
    "        # 3. policy improvement----------------------------------------------------\n",
    "        policy_stable=True\n",
    "        for s in range(nS):\n",
    "            if s in env.goals: π[s]=0; continue\n",
    "            Qs = Q[s]\n",
    "            for a in range(nA):\n",
    "                Q[s,a]=0\n",
    "                for sn in range(nS):\n",
    "                    for rn, r in enumerate(rewards):\n",
    "                        Q[s,a] += p[sn,rn, s,a]*(r + γ*V[sn])\n",
    "                        \n",
    "                if abs(Q[s,a]-Qs[a]) > 1e-4: policy_stable=False\n",
    "            π[s] = Qs*0 + ε/nA\n",
    "            π[s,Q[s].argmax()] += 1-ε     # greedy step  \n",
    "        if policy_stable: print('policy improvement stopped @ iteration %d:'%j); break\n",
    "\n",
    "    return π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "badb2038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x36 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy evaluation stopped @ iteration 27:\n",
      "policy improvement stopped @ iteration 1:\n",
      "[[0.   0.  ]\n",
      " [0.05 0.95]\n",
      " [0.05 0.95]\n",
      " [0.05 0.95]\n",
      " [0.05 0.95]\n",
      " [0.05 0.95]\n",
      " [0.   0.  ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "env=randwalk(figsize=[25,.5])\n",
    "π = Policy_iteration_stoch(env=env)\n",
    "print(π)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e2b2acf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x36 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.render(underhood='Q', Q=π)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7efb676",
   "metadata": {},
   "source": [
    "As we can see the policy chooses to take right majority of the times  1-ε+ ε/nA=.95 while taking left occasionally  ε/nA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6bc2db",
   "metadata": {},
   "source": [
    "## Value Iteration Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c46f87",
   "metadata": {},
   "source": [
    "Our final step to fully develop the ideas of dynamic programming is to shorten the time it takes for a policy to be evaluated and improved. One simple idea we will follow here is to slightly improve the evaluation and immediately improve the policy. We do these two steps iteratively until our policy has stopped to improve. This is a very effective strategy because we do not wait until the policy is fully evaluated to improve it; we weave and interleave the two loops together in one loop. Below we show this algorithm. Read section 4.4 to further your understanding of this algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d32f9fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1) # change the seed to get a different dynamics\n",
    "\n",
    "def π(Q):\n",
    "    return [Q[s].argmax() for s in range(Q.shape[0])]\n",
    "\n",
    "def value_iteration(env=randwalk(), v0=.01, θ=1e-4, γ=.99, isrand=False, show=False): \n",
    "    # initialise V randomly but make sure that terminal states = 0\n",
    "    nS, nA, nR, i = env.nS, env.nA, env.nR, 0\n",
    "    V = np.ones( nS    )*v0; V[env.goals] = 0 \n",
    "    Q = np.ones((nS,nA))*v0; Q[env.goals] = 0 \n",
    "\n",
    "    # p is a 4-d dynamics\n",
    "    if isrand: p = dynrand(nS, nA, nR); rewards = [-1,1] \n",
    "    else:      p = dynamics(env, show); rewards =  env.rewards_set()\n",
    "    \n",
    "    while True:\n",
    "        Δ = 0\n",
    "        i+= 1\n",
    "        for s in range(nS):\n",
    "            v, Q[s] = V[s], 0\n",
    "            for a in range(nA):\n",
    "                for sn in range(nS):\n",
    "                    for rd, rn in enumerate(rewards):\n",
    "                        Q[s,a] += p[sn,rd,  s,a]*(rn + γ*V[sn])  # max operation is embedded now in the evaluation\n",
    "            V[s] = Q[s].max()                                    # step which made the algorithm more concise \n",
    "            Δ = max(Δ, abs(v-V[s]))\n",
    "            \n",
    "        if Δ<θ: print('loop stopped @ iteration: %d , Δ = %2.f'% (i, Δ)); break\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4688661d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop stopped @ iteration: 6 , Δ =  0\n",
      "optimal action for state [0, 1, 1, 1, 1, 1, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "env = randwalk()\n",
    "policy = π(value_iteration(env))\n",
    "print('optimal action for state', policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5af1268c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x36 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.render(underhood='π', π=policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730b962a",
   "metadata": {},
   "source": [
    "As we can see our value iteration algorithm is effective in finding the optimal policy. Note that for the random walk environment the best policy is to move right to get a reward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78362bf8",
   "metadata": {},
   "source": [
    "### Value Iteration on a Grid World"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe4dba3",
   "metadata": {},
   "source": [
    "Now that you understand the value-iteration algorithm, you can apply it on a different and more complex envornment such as the grid world. As we did for the random walk, you have access to a grid world via the Grid class and its subroutines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "585210ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop stopped @ iteration: 10 , Δ =  0\n",
      "optimal action for state [1, 1, 1, 1, 1, 1, 3, 0, 0, 0, 1, 1, 1, 1, 1, 1, 3, 0, 0, 0, 1, 1, 1, 1, 1, 1, 3, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "env=grid()\n",
    "policy = π(value_iteration(env))\n",
    "print('optimal action for state', policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8572e080",
   "metadata": {},
   "source": [
    "To interpret the policy we provided you with a useful funciton to rebder the environemt with its policy, we show that below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bed3a519",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.render(underhood='π', π=policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b22a652",
   "metadata": {},
   "source": [
    "As we can see the policy-iteration algorithm successfuly gave us the best policy for this simple environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d551da9b",
   "metadata": {},
   "source": [
    "### Value Iteration on a Windy Grid World\n",
    "Below we show the results of applying the value iteration method on a windy grid world. This is almost identical to the previous simple grid world without any obstacles, the only difference is that there is a wind blowing upwards, which shifts the agent 2 or 1 cell depending on its location. See page 130 of the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8f4feb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env=windy()\n",
    "policy = π(value_iteration(env))\n",
    "print('optimal action for state', policy)\n",
    "env.render(underhood='π', π=policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d4220a",
   "metadata": {},
   "source": [
    "### value iteration on a maze\n",
    "Let us now apply the policy-iteration on the maze env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "794028d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env=maze()\n",
    "policy = π(value_iteration(env))\n",
    "print('optimal action for state', policy)\n",
    "env.render(underhood='π', π=policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4463cf",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this lesson, we covered the main dynamic programming algorithms. We saw how evaluating a policy was extremely useful in being the key component to allowing us to improve the policy. We then developed a policy iteration algorithm which improves the policy in two main steps:\n",
    "1. a step that evaluates the policy fully to reach an accurate estimation of the action values of the current policy\n",
    "2. a step that improves the policy by adopting a greedy action. The usage of an action-value function Q(s,a) was key in allowing us to choose between actions since the state-value function V(s) does not differentiate between the values of actions\n",
    "\n",
    "We finally saw how the value-iteration algorithm has a similar structure to the policy-iteration algorithm with one important difference; it can arrive at an optimal policy by just taking a step *towards* the optimal policy by slightly refines its estimation of the action-value function without fully evaluating it.  Hence, it improves its policy more concisely and with much less overhead than the full policy iteration method.\n",
    "\n",
    "In the next lesson, we will take a different approach and move to cover sampling methods that do not use the dynamics of the environment explicitly and instead try to improve its policy by interacting with the environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3383f3",
   "metadata": {},
   "source": [
    "## Your turn\n",
    "Try the policy iteration on the maze8 which allows the agent to move diagonally, it is fun."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2bef3e",
   "metadata": {},
   "source": [
    "You should arrive to an optimal policy for this maze environment where agent can move diagonally and has 8 actions. You should be able to observe how efficient the policy is and how the agent is able to reach the goal location from anywhere in the environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4348c6aa",
   "metadata": {},
   "source": [
    "## Challenges\n",
    "1. Alter policy_iteration_stoch to use a softmax policy instead of the ε-greedy policy that we used in the policy_iteration_stoch method.\n",
    "2. You can challenge yourself also by trying to combine policy_iteration and policy_iteration_stoch() in one method. Use a flag such as ε_greedy to distinguish between deterministic and probabilistic policies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
