{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6f91285",
   "metadata": {},
   "source": [
    "step 1 run roscore to prevent losing of training data\n",
    "\n",
    "step 2 roslaunch turtlebot3_gazebo turtlebot3_simple.launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "622dd12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rospy as ros\n",
    "import os\n",
    "from sensor_msgs.msg import LaserScan\n",
    "import numpy as np\n",
    "from numpy import Inf\n",
    "from geometry_msgs.msg import Twist, Pose\n",
    "from nav_msgs.msg import Odometry\n",
    "from std_srvs.srv import Empty\n",
    "from gazebo_msgs.srv import SpawnModel\n",
    "import random\n",
    "from math import atan2, pi\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970b40b6",
   "metadata": {},
   "source": [
    "Author: Abdulrahman Altahhan, Jan 2023.\n",
    "\n",
    "The notebook use a library of functionality in RL that aims for simplicity and general insight into how algorithms work, these libraries are written from scratch using standard python libraries (numpy, matplotlib etc.).\n",
    "Please note that you will need to take a permission from the author to use the code for research, commercially or otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b352bd",
   "metadata": {},
   "source": [
    "# Lesson 11: RL on Robotics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20d482b",
   "metadata": {},
   "source": [
    "**Learning outcomes**\n",
    "1. understand how to create a simple Robot environment that links to Gazebo\n",
    "1. understand how to deal with the simulated environment in a grid world fashion\n",
    "1. appreciate the intricacy of applying RL to the robotics domain\n",
    "1. build on previous concepts to come up with a suitable solution to a problem at hand\n",
    "1. understand how a replay buffer helps us to come closer to supervised learning and appreciate the important role it plays in reaching convergence\n",
    "1. understand how to combine deep reinforcement learning with deep learning to create a powerful framework that allows automatic agent learning by observation or self-play.\n",
    "1. understand how a replay buffer helps us to come closer to supervised learning and appreciate the important role it plays in reaching convergence for difficult problems that involve image processing and reinforcement learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbe78bc",
   "metadata": {},
   "source": [
    "**Reading**:\n",
    "We cover applications of RL on robotics based on previouse units which you can refere to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef686b3",
   "metadata": {},
   "source": [
    "In this notebook, we deal with how to set up a robot environment class that can handle the publish-subscribe on topics and deal with services in ROS. We must have ROS and Gazebo installed and set up on our machine. The code is a starting point and is not fully developed. You will need to write the necessary functionality to address a specific requirement. The main idea of tackling robotics applications in a Jupyter notebook is to utilise the provided infrastructure and libraries of code we covered in earlier units."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6e65a6",
   "metadata": {},
   "source": [
    "## Running Gazebo\n",
    "You will need to launch a gazebo environment with Turtlebot3 in it. So long as the /scan(LaserScan), /odom (Odometry) and /cmd_vel(Twist) topics are available, the environment should work fine. Our target is to build an environment that will allow us to use the algorithms we developed in earlier units directly.\n",
    "\n",
    "To launch an environment, you should open a terminal and run the following command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7112d011",
   "metadata": {},
   "source": [
    "roslaunch turtlebot3_gazebo turtlebot3_house.launch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1838aceb",
   "metadata": {},
   "source": [
    "Note that you cannot do that here because that will block the notebook from executing other code. \n",
    "You must select restart your notebook kernel, ex. Kernel-> Restart and Run ALL, whenever you want to re-establish a connection with the environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cf31b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f5bf1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rospy as ros\n",
    "from sensor_msgs.msg import LaserScan\n",
    "import numpy as np\n",
    "from numpy import Inf\n",
    "from geometry_msgs.msg import Twist\n",
    "from nav_msgs.msg  import Odometry\n",
    "from std_srvs.srv import Empty\n",
    "import random\n",
    "from math import pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c47912ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global hyperparamter how many areas full cricle divided\n",
    "θres = 10\n",
    "# global hyperparamter how times publisher publisehs\n",
    "hz = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab2f807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoboGridEnv:\n",
    "    \n",
    "    # the goals default values are set just in front of the robot for testing, \n",
    "    # change according to the brief and as you see fit\n",
    "    def __init__(self, xdim=4, ydim=4, hz=hz,  \n",
    "                 xgoal=1.3, ygoal=0, tol=0.5,\n",
    "                 speed=0.3, θspeed=1,\n",
    "                 resol=3, θresol=2*pi/θres,\n",
    "                 range_min=0.30,\n",
    "                 rewards=[100, -10, 0, -1,],\n",
    "                 visual=False):\n",
    "        \n",
    "        ros.init_node('RoboEnv')\n",
    "        ros.loginfo('Robot Environment node has been created')\n",
    "        \n",
    "        self.sub_scan = ros.Subscriber('/scan', LaserScan, self.scan, queue_size=None)\n",
    "        self.sub_odom = ros.Subscriber('/odom', Odometry, self.odom, queue_size=1)\n",
    "        self.pub_robot = ros.Publisher('/cmd_vel', Twist, queue_size=1)\n",
    "        \n",
    "        self.Vstar = None # for compatibility\n",
    "        \n",
    "        #visual\n",
    "        self.visual = visual\n",
    "        \n",
    "        # coordinates of the goal must be changed to match the given environment\n",
    "        self.xgoal = xgoal\n",
    "        self.ygoal = ygoal\n",
    "        \n",
    "        #size of env         \n",
    "        self.xdim = xdim\n",
    "        self.ydim = ydim\n",
    "        \n",
    "                 \n",
    "        # $ rostopic hz /scan, rostopic hz /odom\n",
    "        self.hz = hz  # frequency of scan\n",
    "        self.rate = ros.Rate(self.hz)\n",
    "        \n",
    "        self.speed = speed    # linear speed, change as you see fit\n",
    "        self.θspeed = θspeed # angular speed, change as you see fit\n",
    "        self.tol = tol     # tolerance to goal recognition, within 2 feet\n",
    "        \n",
    "        self.resol = round(resol,2)\n",
    "        self.θresol = round(θresol,2)\n",
    "        \n",
    "        self.cols = int(self.xdim//self.resol) +1\n",
    "        self.rows = int(self.ydim//self.resol) +1\n",
    "        self.orts = int(2*pi//self.θresol)     +1\n",
    "        \n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.θ = None\n",
    "        self.scans = None\n",
    "        \n",
    "\n",
    "        self.nC = self.rows*self.cols           # Grid size\n",
    "        self.nS = self.rows*self.cols*self.orts # State space size\n",
    "        self.nA = 3\n",
    "        \n",
    "        self.range_max = 3.5\n",
    "        self.range_min = .25  # change as you see fit\n",
    "        \n",
    "        print('Grid  size = ', self.rows,'x', self.cols,'=', self.nC)\n",
    "        print('State size = ', self.rows,'x', self.cols, 'x', self.orts,'=',self.nS)\n",
    "        \n",
    "        self.robot = Twist()\n",
    "\n",
    "    # change as you see fit\n",
    "    def scan(self, scans):\n",
    "        scans = np.array(scans.ranges)\n",
    "        scans[scans==Inf] = self.range_max\n",
    "        # print('scans = ', scans[:10].round(2))\n",
    "        self.scans = scans\n",
    "        self.rate.sleep()\n",
    "    \n",
    "    # change the reward to produce a suitable policy\n",
    "    def reward(self):\n",
    "        reward = -1\n",
    "        done = False\n",
    "        \n",
    "        # cheacking for goal\n",
    "        tol = self.tol \n",
    "        if self.xgoal + tol > self.x > self.xgoal - tol and self.ygoal + tol > self.y > self.ygoal - tol: \n",
    "            reward =  100 \n",
    "            done = True\n",
    "        \n",
    "        # add code to make your robot stops when it hit a wall\n",
    "        \n",
    "        return reward, done\n",
    "    \n",
    "    # change as you see fit\n",
    "    def odom(self, odoms):\n",
    "        self.x = round(odoms.pose.pose.position.x, 1)   \n",
    "        self.y = round(odoms.pose.pose.position.y, 1)   \n",
    "\n",
    "        self.rate.sleep() \n",
    "    \n",
    "    # change this to generate a suitable state representation\n",
    "    def s_(self):\n",
    "         # the return is provided for testing only\n",
    "         # you must return the state of the robot instead\n",
    "        return random.randint(0, self.nS)\n",
    "    \n",
    "    def reset(self):\n",
    "#         reset_world service\n",
    "        try:    ros.ServiceProxy('/gazebo/reset_world', Empty).call()\n",
    "        except: print('could not reset world')\n",
    "        self.rate.sleep()\n",
    "        self.done = False\n",
    "        return self.s_()\n",
    "\n",
    "    def step(self, a):\n",
    "        \n",
    "        # commented out for testing\n",
    "        if a==0: self.left(self.θspeed)\n",
    "        if a==1: self.forward()\n",
    "        if a==2: self.right(self.θspeed)\n",
    "            \n",
    "#         self.forward() # comment this out, as it will force the robot always to move forward\n",
    "        \n",
    "        self.s = self.s_() # get the stat\n",
    "        self.r, self.done = self.reward()\n",
    "        return self.s, self.r, self.done, {}\n",
    "    \n",
    "    def nodeslist(self):\n",
    "        nodes = os.popen('rosnode list').readlines()\n",
    "        for i in range(len(nodes)):\n",
    "            nodes[i] = nodes[i].replace('\\n', '')\n",
    "            print(nodes[i])\n",
    "    \n",
    "    # for compatibility, no need to change\n",
    "    def render(self, **kw):\n",
    "        pass\n",
    "    \n",
    "    def left(self, θspeed):\n",
    "        self.robot.linear.x  =  0\n",
    "        self.robot.angular.z = θspeed\n",
    "        self.pub_robot.publish(self.robot)\n",
    "        self.rate.sleep()\n",
    "    def forward(self):\n",
    "        self.robot.linear.x  = self.speed\n",
    "        self.robot.angular.z =  0\n",
    "        self.pub_robot.publish(self.robot)\n",
    "        self.rate.sleep()\n",
    "    def right(self, θspeed):\n",
    "        self.robot.linear.x  =  0\n",
    "        self.robot.angular.z =-θspeed\n",
    "        self.pub_robot.publish(self.robot)\n",
    "        self.rate.sleep()\n",
    "    def stop(self):\n",
    "        self.robot.linear.x = 0\n",
    "        self.robot.angular.z = 0\n",
    "        self.pub_robot.publish(self.robot)\n",
    "        self.rate.sleep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1674d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1682629561.690200, 73.363000]: Robot Environment node has been created\n",
      "Grid  size =  10 x 10 = 100\n",
      "State size =  10 x 10 x 10 = 1000\n"
     ]
    }
   ],
   "source": [
    "robogrid2x2 = RoboGridEnv(xdim=4, ydim=4,\n",
    "                          xgoal=1.5, ygoal=0, tol =0.6,\n",
    "                          speed=0.2, θspeed=1, hz=hz,\n",
    "                          resol=0.4, θresol=(2*pi/θres),\n",
    "                          range_min=0.38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fada64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def revolve(env):\n",
    "    env.visual = True\n",
    "    env.reset()\n",
    "    env.step(-1)\n",
    "    for i in range(15):\n",
    "        env.step(0)\n",
    "        env.stop()\n",
    "        plt.pause(1)\n",
    "        \n",
    "    env.visual = False\n",
    "revolve(robogrid2x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6cfb169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def straight(env):\n",
    "    env.visual = True\n",
    "    env.reset()\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        done = env.step(1)[2]\n",
    "    \n",
    "    env.stop()\n",
    "    env.visual= False\n",
    "        \n",
    "straight(robogrid2x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95df35a0",
   "metadata": {},
   "source": [
    "## Training Headless\n",
    "To train more efficiently, turn off the gui in gazebo. To do so, go to the .launch file that you have launched gazebo with and set the values of gui and headless as follows:\n",
    "\n",
    "    <arg name=\"gui\" value=\"false\"/>\n",
    "    <arg name=\"headless\" value=\"true\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cc5402",
   "metadata": {},
   "source": [
    "Now it is time to apply Sarsa on robotics! Note that this will not generate a useful policy yet. You must adjust the above code and tune your RL method hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a464e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from Lesson5_TemporalDifferenceMethods import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c33a114a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env=RoboGridEnv()\n",
    "sarsa = Sarsa(env=env, α=.1, episodes=10, seed=10, **demoGame()).interact()\n",
    "env.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2783e834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df028fe3",
   "metadata": {},
   "source": [
    "Continue by adding more cells to address the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e057d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rospy as ros\n",
    "import numpy as np\n",
    "from numpy import Inf\n",
    "from geometry_msgs.msg import Twist\n",
    "from nav_msgs.msg  import Odometry\n",
    "from std_srvs.srv import Empty\n",
    "from time import sleep\n",
    "import math\n",
    "from sensor_msgs.msg import LaserScan\n",
    "\n",
    "class Env:\n",
    "    def __init__(self):hz\n",
    "        ros.init_node('Env')\n",
    "        ros.loginfo('Env node has been created')\n",
    "        self.sub_odom = ros.Subscriber('/odom', Odometry, self.odom_callback, queue_size=1)\n",
    "        self.pub_robot = ros.Publisher('/cmd_vel', Twist, queue_size=1)\n",
    "        # self.sub_scan = ros.Subscriber('/scan', LaserScan, self.scan, queue_size=None)\n",
    "        \n",
    "        # $ rostopic hz /scan\n",
    "        # $ rostopic hz /odom\n",
    "        self.rate = ros.Rate(5) # 5 is the frequency of scan (we can reduce here to reduce the overhead but responsiveness will degrade)\n",
    "        self.robot = Twist()\n",
    "        \n",
    "        # Initialize position and orientation variables\n",
    "        self.x = 0.0\n",
    "        self.y = 0.0\n",
    "        self.θ = 0.0\n",
    "        \n",
    "        self.current_yaw = 0\n",
    "        self.max_increase = 0.45\n",
    "        self.z_rotate = 0\n",
    "\n",
    "        self.range_max = 3.5\n",
    "        self.range_min = .25 # extra safty buffer to stop a bit early\n",
    "\n",
    "    def step(self, a):\n",
    "        if a==1:\n",
    "            self.rotate('down')\n",
    "        if a==0:\n",
    "            self.rotate('right')\n",
    "        if a==3:\n",
    "            self.rotate(\"up\")\n",
    "        if a==2:\n",
    "            self.rotate(\"left\")\n",
    "        \n",
    "        self.forward(a)\n",
    "            \n",
    "        self.pub_robot.publish(self.robot)\n",
    "        self.rate.sleep()\n",
    "    \n",
    "    def scan(self, scans):\n",
    "        scans = np.array(scans.ranges)\n",
    "        scans[scans==Inf] = self.range_max\n",
    "        print('scans = ', scans[:10].round(2))\n",
    "           \n",
    "        self.done = scans.min() < self.range_min\n",
    "        # if scans[:3].min() < self.range_min or scans[-3:].min() < self.range_min:\n",
    "        #     self.left()\n",
    "\n",
    "        self.scans = scans\n",
    "        self.pub_robot.publish(self.robot)\n",
    "        self.rate.sleep()\n",
    "\n",
    "    def forward(self, a):\n",
    "    # Move the robot forward for one second\n",
    "        increase = 0.4\n",
    "        if (a==0):\n",
    "            increase = 0.6\n",
    "    \n",
    "        self.robot.linear.x = 0.14 * (increase + self.max_increase)\n",
    "        self.robot.angular.z = 0 \n",
    "        self.pub_robot.publish(self.robot)\n",
    "\n",
    "    # Sleep for one second\n",
    "        sleep(1)\n",
    "\n",
    "    # Stop the robot\n",
    "        self.robot.linear.x = 0\n",
    "        self.robot.angular.z = 0\n",
    "        self.pub_robot.publish(self.robot)\n",
    "    \n",
    "    def normalize_angle(self, angle):\n",
    "        while angle > math.pi:\n",
    "            angle -= 2 * math.pi\n",
    "        while angle < -math.pi:\n",
    "            angle += 2 * math.pi\n",
    "        return angle\n",
    "    \n",
    "    def rotate(self, direction):\n",
    "        if direction == 'down':\n",
    "            target_yaw = 0\n",
    "        elif direction == 'left':\n",
    "            target_yaw = math.radians(90)\n",
    "        elif direction == 'up':\n",
    "            target_yaw = math.radians(180)\n",
    "        elif direction == 'right':\n",
    "            target_yaw = math.radians(270)\n",
    "        else:\n",
    "            raise ValueError('Invalid direction, must be \"down\", \"left\", \"up\", or \"right\".')\n",
    "\n",
    "        angle_tolerance = 0.015  # Adjust this value based on the required precision\n",
    "        angular_velocity = 0.14  # rad/s, set this to the desired angular velocity\n",
    "\n",
    "        target_yaw = self.normalize_angle(target_yaw)\n",
    "        current_yaw_normalized = self.normalize_angle(self.current_yaw)\n",
    "\n",
    "        while abs(current_yaw_normalized - target_yaw) > angle_tolerance:\n",
    "            clockwise_angle_diff = (current_yaw_normalized - target_yaw) % (2 * math.pi)\n",
    "            counterclockwise_angle_diff = (target_yaw - current_yaw_normalized) % (2 * math.pi)\n",
    "\n",
    "            if clockwise_angle_diff < counterclockwise_angle_diff:\n",
    "                self.robot.angular.z = -angular_velocity  # Rotate clockwise\n",
    "            else:\n",
    "                self.robot.angular.z = angular_velocity  # Rotate counterclockwise\n",
    "\n",
    "            self.pub_robot.publish(self.robot)\n",
    "            self.rate.sleep()\n",
    "            current_yaw_normalized = self.normalize_angle(self.current_yaw)\n",
    "\n",
    "        self.robot.angular.z = 0  # Stop rotating\n",
    "\n",
    "    def odom_callback(self, odoms):\n",
    "        self.z = round(odoms.pose.pose.orientation.z, 3)\n",
    "        self.w = round(odoms.pose.pose.orientation.w, 3)\n",
    "        self.current_yaw = math.atan2(2 * (self.w * self.z), 1 - 2 * (self.z**2))\n",
    "    \n",
    "    def stop(self):\n",
    "        self.robot.linear.x = 0\n",
    "        self.robot.angular.z = 0\n",
    "        self.pub_robot.publish(self.robot)\n",
    "        self.rate.sleep()\n",
    "    \n",
    "    def resetPos(self):\n",
    "        # Initialize position and orientation variables\n",
    "        self.x = 0.0\n",
    "        self.y = 0.0\n",
    "        self.θ = 0.0\n",
    "\n",
    "        self.odom_prev = None\n",
    "\n",
    "    def reset(self):\n",
    "        self.done = False\n",
    "        # reset_world service\n",
    "        # $ rosservice list\n",
    "        # $ rosservice info /gazebo/reset_world\n",
    "        # $ rossrv show std_srvs/Empty # yeilds nothing meaning we can call() without passing arguemnt\n",
    "        try:\n",
    "            ros.ServiceProxy('/gazebo/reset_world', Empty).call()\n",
    "        except:\n",
    "            print('could not reset world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac149eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVwAAAEGCAYAAAApAy29AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABOXUlEQVR4nO2deXxU5fX/38/MJJN9T1iSQNgR2QREEEVRVKS2uG91qdraRW39aq3WWq3bT23rUlv31qq1rtWqdUNEBFcg7DuEPQmEhOz7LM/vj7tkJpksE8iCOe8XeTF57p17z9zMfObc85znHKW1RhAEQeh6HD1tgCAIQl9BBFcQBKGbEMEVBEHoJkRwBUEQugkRXEEQhG7C1dMGdJa0tDSdk5PT02YIgiAEsWLFihKtdXqobUes4Obk5JCbm9vTZgiCIAShlNrd2jYJKQiCIHQTIriCIAjdhAiuIAhCN3HExnAFQeh6PB4P+fn51NfX97QpvY6oqCiysrKIiIjo8HNEcAVBaJX8/Hzi4+PJyclBKdXT5vQatNYcPHiQ/Px8hgwZ0uHnSUhBEIRWqa+vJzU1VcS2GUopUlNTw/b8RXAFQWgTEdvQdOa6iOCGyftrCymvbexpMwRBOAIRwQ2DvaW1XP/KKm54dVVPmyIIfZrHHnuM2tranjYjbERww8DnN4q1N3j9PWyJIPRtRHD7AMkxkQCccXT/HrZEEPoGNTU1fO9732PChAmMHTuW119/nccff5zCwkJmzZrFrFmzAPjkk0+YPn06kyZN4oILLqC6uhowSgD85je/Ydy4cUydOpW8vDwA3nzzTcaOHcuECROYOXNmt70eSQsLA2V+PUlbIqGvctEz37QYO2v8AC6fnkNdo48f/XNZi+3nT87iginZlNY08vOXVwRte/2n09s838cff8zAgQP54IMPAKioqCAxMZFHHnmERYsWkZaWRklJCffddx+ffvopsbGxPPTQQzzyyCPceeedACQmJrJu3TpeeuklbrzxRt5//33uuece5s+fT2ZmJuXl5Z28GuEjHm4Y1DR4AXDIrK0gdAvjxo1jwYIF3HrrrXzxxRckJia22Ofbb79l48aNzJgxg4kTJ/Liiy+ye3dT/ZhLLrnE/v+bb4wvjBkzZvCjH/2I5557Dp/P1z0vBvFww8KK4cZFyWUT+iZteaTRkc42t6fERrbr0TZn5MiRrFy5kg8//JA77riDU0891fZcLbTWnHbaabz66qshjxGYvmU9fvrpp1m6dCkffPABkydPZsWKFaSmpoZlW2cQDzcMvD5DcLcXV/ewJYLQNygsLCQmJobLLruMW265hZUrVwIQHx9PVVUVANOmTeOrr76y47M1NTVs3brVPsbrr79u/z99uiH427dv57jjjuOee+4hPT2dvXv3dsvrEVctDDw+Izth4aYD/PbMo3rYGkH47rNu3TpuueUWHA4HERERPPXUUwBce+21zJkzh4EDB7Jo0SJeeOEFLrnkEhoaGgC47777GDlyJABlZWWMHz8et9tte8G33HIL27ZtQ2vNqaeeyoQJE7rl9agjdQJoypQpursLkG8rquK0R5cwPCOOT286qVvPLQg9waZNmzjqqCPXubAaFaSlpXXJ8UNdH6XUCq31lFD7txtSUEplK6UWKaU2KqU2KKV+ZY6nKKUWKKW2mf8nm+NKKfW4UipPKbVWKTUp4FhXmvtvU0pdGTA+WSm1znzO46qXriWMjnQCkBYX2cOWCIJwJNKRGK4XuFlrPQaYBlynlBoD3AYs1FqPABaavwOcCYwwf64FngJDoIG7gOOAqcBdlkib+/wk4HlzDv2lHX4GJkYDMG1o1wfXBUE4dHbt2tVl3m1naFdwtdb7tNYrzcdVwCYgE5gHvGju9iJwtvl4HvCSNvgWSFJKDQDOABZorUu11mXAAmCOuS1Ba/2tNuIbLwUcq1dh+d1HaBRGEDrFkRp27Go6c13CylJQSuUAxwBLgX5a633mpv1AP/NxJhA45ZdvjrU1nh9iPNT5r1VK5SqlcouLi8Mx/bCwo6QGgAGJUd1+bkHoCaKiojh48KCIbjOserhRUeFpQYezFJRSccBbwI1a68rAMKvWWiuluvwvorV+FngWjEmzrj5fcxrNGgpJMR2v8C4IRzJZWVnk5+fTEw5Ob8fq+BAOHRJcpVQEhtj+W2v9tjlcpJQaoLXeZ4YFDpjjBUB2wNOzzLEC4ORm45+b41kh9u91+M1v+bX5FcwZO6CHrRGEriciIiKsjgZC23QkS0EB/wA2aa0fCdj0HmBlGlwJvBswfoWZrTANqDBDD/OB05VSyeZk2enAfHNbpVJqmnmuKwKO1auw7qo+2VjUs4YIgnBE0hEPdwZwObBOKbXaHLsdeBB4Qyl1DbAbuNDc9iEwF8gDaoGrALTWpUqpe4Hl5n73aK1Lzce/AF4AooGPzJ9eh1/iWIIgHALtCq7W+kugtbzYU0Psr4HrWjnW88DzIcZzgbHt2dLTJEQZsVvJwxUEoTNILYUwyEmLJTbSydEDW1YsEgRBaA8R3DBxKCV5uIIgdAoR3DBYuaeMqgYvkwcnt7+zIAhCM0Rww8Bj5uEmSx6uIAidQAQ3DMz643yz42DPGiIIwhGJCG4YWMsb52/Y38OWCIJwJCKCGwZ+mSwTBOEQEMENg/R4N2D0ZhIEQQgXEdwwGNU/nv4JUQxOie1pUwRBOAIRwQ0Th5IlvoIgdA4R3DD4bHMRhRX1zJsYslyvIAhCm4jghoHZtFfq4QqC0ClEcMPACiV8ImlhgiB0AhHcMGjKw5V6uIIghI8IbhhIHq4gCIeCCG4YDEqJASAxWmK4giCEjwhuGIzNTGRERhxp8bLwQRCE8BHBDQOfX+Px+fFJbEEQhE4gghsG760pYNfBWm6cPbKnTREE4QhEBDcM/GYebmxkh7rLC4IgBCGCGwZWHu6bK/b2sCWCIByJiOCGgVVC4RPJwxUEoROI4IaBRibLBEHoPCK4YTC6fwIAMW5nD1siCMKRiMz+hMGE7CQmDUoi1i2XTRCE8BEPNwzqPT7K6zyShysIQqcQVy0MXl++lx3FNbzx0+k9bYogCEcg4uGGgZUW5nKoHrZEEIQjERHcMLAiCX//YmfPGiIIwhGJCG4YWPVwP90kebiCIISPCG4YSPNIQRAOBRHcMDg2JwUAl1NiuIIghI8IbhgcMyiZk0am43TIZRMEIXxEOcKgos5DSXUDkeLhCoLQCSQPNwxe+noXGworybv/zJ42RRCEIxDxcMPASgtzKPFwBUEIHxHcMLCyFP44f0sPWyIIwpGICG4YWHm4n2850MOWCIJwJNKu4CqlnldKHVBKrQ8Y+4NSqkAptdr8mRuw7bdKqTyl1Bal1BkB43PMsTyl1G0B40OUUkvN8deVUr22Ja4VUpB8XEEQOkNHPNwXgDkhxh/VWk80fz4EUEqNAS4Gjjaf86RSyqmUcgJPAGcCY4BLzH0BHjKPNRwoA645lBfUlcwanQE0Ca8gCEI4tCu4WuslQGkHjzcPeE1r3aC13gnkAVPNnzyt9Q6tdSPwGjBPKaWAU4D/mM9/ETg7vJfQfUwenMxZ4weIhysIQqc4lBju9UqptWbIIdkcywQCOyzmm2OtjacC5Vprb7PxkCilrlVK5SqlcouLiw/B9M5xoLKeA5UNJEVHdPu5BUE48ums4D4FDAMmAvuAhw+XQW2htX5Waz1Faz0lPT29O04ZxN+/3Mm6ggre/sWMbj+3IAhHPp1a+KC1tstlKaWeA943fy0AsgN2zTLHaGX8IJCklHKZXm7g/r0Ov18jpXAFQegsnfJwlVIDAn49B7AyGN4DLlZKuZVSQ4ARwDJgOTDCzEiIxJhYe08beVaLgPPN518JvNsZm7oDv4aaRh+3vbW2p00RBOEIpF0PVyn1KnAykKaUygfuAk5WSk0ENLAL+CmA1nqDUuoNYCPgBa7TWvvM41wPzAecwPNa6w3mKW4FXlNK3QesAv5xuF7c4caaLPtiW0kPWyIIwpFIu4Krtb4kxHCroqi1vh+4P8T4h8CHIcZ3YGQx9HqshQ+SpSAIQmeQlWZhMO+YTKIiHIjeCoLQGURww2DSoGTOOSZTPFxBEDqFCG4Y7CqpYV9FPZnJ0T1tiiAIRyBSDzcMnl68nU37Kll6++yeNkUQhCMQ8XDDwK+11MIVBKHTiOCGgV/Dvop6fvzi8p42RRCEIxAR3DCwJsuW7uxoLR9BEIQmRHDDwEpOkCQFQRA6gwhuGPzo+ByGZ8TZCyAEQRDCQQQ3DCZkJ3HK6AwpQC4IQqcQwQ2DDYUVFJTVMXpAfE+bIgjCEYjk4YbBE4vy2FZUzYKbTuppUwRBOAIRDzcM/H4kD1cQhE4jghsGfq3ZUlTFvCe+6mlTBEE4AhHBDQNrsmxtfnmP2iEIwpGJCG4YWOlgWiOpYYIghI0Ibhj832kjOWmk0bxS9FYQhHARwQ2DsZmJTBlsdISXmriCIISLCG4YLNtZyp7SWqbmpCByKwhCuEgebhj89bNt1DR4efsXM3raFEEQjkDEww0DqYcrCMKhIIIbBn4/5O4u45SHP6eu0dfT5giCcIQhghsG1kTZjuIafDJpJghCmIjghkGgxkqWgiAI4SKCGwb3nj2Wi4/NBkD7e9gYQRCOOERww2BU/3hG9TdKM2pJDBMEIUxEcMPg041F7D5Yy6xR6Tgckq0gCEJ4SB5uGPz1s20kx0bywlVTe9oUQRCOQMTDDQO/lnq4giB0HhHcMPBrzWebD3Dc//uUA1X1PWZHSXUD93+wEa/PmLnz+vx8vH6fVDAThF6OCG4YWPVwiyob8PVgJ8knF23nuS92smxXKQDPLNnBz15eycfr9/eYTYIgtI8IbhgEepA92bl3bGYCAJlJ0QAUltcBUFLT2GM2CYLQPiK4YfD0ZZO5cfYIAPw9qLhe89xOM1NiSFosADmpMT1mkyAI7SOCGwY5abFkJRui1pPh0sVbiwHYvK8KgDEDE5g2NMUWXkEQeiciuGHw9sp8dpZUc9b4AURHOnvMDo/XmCyz6jlMzE7i92eNITE6osdsEgShfURww+Cvn+Wxt7SOv106ifR4d4/Zcfn0wQCkxEYCsGlfFd97/EtW7invMZsEQWgfEdwwMOrh9rQVTbFbK1Pio3X7ACiq6LlUNUEQ2qddwVVKPa+UOqCUWh8wlqKUWqCU2mb+n2yOK6XU40qpPKXUWqXUpIDnXGnuv00pdWXA+GSl1DrzOY8r1XtXFvi15pONRYy9az55B6p7zI4lW0sAqPMYNXmrG7xA02SaIAi9k454uC8Ac5qN3QYs1FqPABaavwOcCYwwf64FngJDoIG7gOOAqcBdlkib+/wk4HnNz9Vr8PuNybLqBm+Plme0Fl2kxwWHNXrvV5UgCNABwdVaLwFKmw3PA140H78InB0w/pI2+BZIUkoNAM4AFmitS7XWZcACYI65LUFr/a02klxfCjhWr0Nrjcu8ne9JwR2cYmQjjBmQYNpljIveCkLvprMx3H5a633m4/1AP/NxJrA3YL98c6yt8fwQ4yFRSl2rlMpVSuUWFxd30vTO89Yvjuf27x0FGN5uT+H1+1EKu2JZWrwxeTZpcHJbTxMEoYc55Ekz0zPtFndPa/2s1nqK1npKenp6d5wyiAGJ0XZmQE96uOsLKtAaFmwsAmBcZiKzj+pHTqrk4QpCb6az5RmLlFIDtNb7zLDAAXO8AMgO2C/LHCsATm42/rk5nhVi/17J81/upN7r4+Jjs0mK6bmcV7fLyAH2mMVrTh6VQUqsm/K6RjLio3rMLkEQ2qazHu57gJVpcCXwbsD4FWa2wjSgwgw9zAdOV0olm5NlpwPzzW2VSqlpZnbCFQHH6nU8+XkeBWV1PHjeeHvFWU/w6zNGAk1ZCQdrGrnwmW/4fHP3h1kEQeg47Xq4SqlXMbzTNKVUPka2wYPAG0qpa4DdwIXm7h8Cc4E8oBa4CkBrXaqUuhdYbu53j9bamoj7BUYmRDTwkfnTK+kt9XCdDuN70qrn8PTn2wFJCxOE3k67gqu1vqSVTaeG2FcD17VynOeB50OM5wJj27OjN+DXmi+2FZNz2we8/YvjmTSoZyapXl9uzD9aAlvbaOTjSut2QejdyEqzMPD7tZ0Z0JPatqukBmiqEmY1tOzJCmaCILSPCG4YaI2dh9uT3RXiolwMTIxispUGZprSk0XRBUFoHxHcMPji1lnccsZooGcLkHt9fpRStkfrjjD+jKceldFzRgmC0C4iuGGQFBNJrNtIyerJPNyS6kYKyut46ZtdABwzKJnLpg1isOThCkKvRtqkh8Gf528hI8HNNScMoX9Cz+W7WosvfKbmnz8pi/Q4NztLaqQIuSD0YsTDDYNnlmxnf0U9vz9rDAXldRz1+4+prPd0ux3/79xxAPjM9cUauOqF5fxvTWG32yIIQscRwQ0DvzbErabByyMLtlLn8bGxsLLb7XDZ9XCN33/zn7WA5OEKQm9HQgph4NeaNXvLOfqu+faYswcqkj+yYCvQ5OHWe408XEkLE4TejXi4YaB1k8CeNNIonjMiI67b7ViXXwHAxGwjLcxnBnNl4YMg9G7Ew+0gVt6tdTs/+6gMfnR8DrHu7r+Efq05bkgKJ4xIA5pCCeLhCkLvRjzcVqhr9JF3oCpobOt9Z3LDqSMAqKz38sLXu3qk1Y7Pr6nz+KizlvSaoYVLpg7qdlsEQeg4IritcP0rK5n9yBIazPioUopIl4NIp3HJVuwuY/HWYkqqG7rdNq9fsza/gscWGrHck0dlcOuc0eSESAkrr23skYk9QRBaIoLbCtbNeYPX8B49Pj93vrueLfur+OWpI9iy3/B+G73d3/ohMzkaaAohXHl8DsPSY1mzt7zFvte/soq5j3/RneYJgtAKfVJwr3h+Gf9eurvNfWaNNpbJ1pudcb0+zUvf7Ka4uoGbThvJiH7GZJlVBLw7eeLSScS7XXbs1ufX3P7f9by2fG+LfYdnxJEQJaF6QegN9EnBXbK1mN/9d32b+9SarccbPIagWkt5/VpzoLLe9mwbesDDBaOfmeXhXvD015RUN4ScNPP4/ES6+uSfWRB6HX3W9Zk3cWCb2x/4aDPQVIHLEtxdJTVM/X8L7f2iI5xdZGHrXP/KSirqPHYamGVjqLSwV5btQWtDeCOcIryC0JP0OcG1vMD2Gi6O7h9PVnKMPRFlOY9Wt4XE6AhcDsXpR/fvOmNbYV2BkYd7ihn2aCstzNJgEVxB6Hn6nOA2mjHX5btK29yvss5D4sCARpEaIp0OIpxGHu6PTxhi58F2N16f5rxJWZwy2uhOb3m4oZb2ThmcTO7uMjxeDZHdaqYgCM3ocy6P2+WgX4K7XW+vsKKet1bms970JhNjIth6/5lcNWMIAOnxbv7fh5t4Z1X3Nxn2+TVltY2U1jQChtAOTYvl5tNHttjXCp14/D0TaxYEoYk+J7hKKVJj3banGorAzIOiyvqgbVbphGU7S1m+q4z8stousbMtvH7NZ5sPcPf/NgBw4ZQsbjh1eMh6uFa/s57IphAEIZg+J7jltY1s3FfJ6r0Vre7j15qLpmQDTVkIlfUebnpjNZv2VXH73NF2HLUn8nCPHpgANIUSrp05jJhIF4u3tmyTbk3+9USRHUEQgulzgmvdhre1QsztcvKLWcOApjzc+kYfb68s4GBNA9fOHGYX+m70dX/9ghevnsqIjDhbcCvrPfx5/hZe/HpXi31nDE9lyuBkMuJbL5h+oLKeeU98xWebi7rKZEEQ6IOC29iBW+uaBi/5ZXVAk4drzUf5NewsqbGFuyc8XDA8VktwZz+8mG0HqkM2kfR4Na42wicAFXUe1uwtZ8HGA11iqyAIBn0uS8FayHDv2WNb3Sd3dxlXPr8MgJjI4B5mpdWNzPrz5/a+AxK7v9XO9x7/gs37q8hMMpb4Ns8VDmSZmY2xZX8Vo/rHhzye9SW0ak9ZV5grCIJJnxNcS1yGtJGHW1FntM1Z8H8zGdHPEClLzAKTG6bmpPCTmUO7yNLW2bSvkuyUaC461ogzW+lg3jbCG7WN3m6xTRCE1ulzIQXLw31vTevpXJbgJkY35eEqpUiOiSDKXFn205lD+eP547vQ0tD4/Rq/hvMmZdmLLtpaaXbOMZkAeNoQ41ChCEEQDj99TnBnDE/l9DH9yN3V+u1zpSm4172y0p6IykyKZtWdp3O2KWBZydE8+NFm7n1/Y5fbHIglqkWV9ewtNVLSPD4/3xs3gEcunNBi/4tNL7ittDDrS6QniqkLQl+izwmuUoqYSGeb7Wgq6jy4XQ42769iZ0lN0DaHMiag3lldyMcb9rP74KHn4X6VV8Jv317XoQk4yxt9ddlebn5zDQC/PHUElx43iKzkmBb7F1UZ2RhtCe7IfvEkRkcwLjOxM+YLgtBB+pzgrtpTxjurC9lfUd/qPt8bN4D7zxlHVITTLkC+v6Ken/4rl42Fldx39lhW7DY85I4uKNBa8/X2ErtVTyBb9lfx6rI9HY6znmguKbbE97pZw6lp8PLfVfkt9v3lq6sASIlte13vl7fO4rdzR3fo/IIgdI4+J7jbzJY4bZVVnJCdxPmTs3C7HHbMt7rBw/wNRZTVNnLZtMEMSzfzcDuYFvbBun1c+tzSkDVrP9m4H4Aac1VYW0RFOPnXNcdx4og0fH6N1pqC8jqe/2onzy3Z2WL/9Hg3l0zNZnxWUqvHXLrjIOc8+TU7imta3UcQhEOnzwluR+rXbiisYEdxNVERzqYW5KZjqoH1BRW2h9yRvF6A2gbjOPtCeNYrd5cDUBdGJoHLofBrTaPPz4wHP+PbHaUh08K8Pj8uR9t/5sp6L3kHqnkjt+WXgSAIh48+N0tieaQLbz6p1X1+85+19EuIYuzABPolGHm2lpg1eHyc9dcv7X3Hmsts2+O4oSkADE5pGWe1qO2Ah1tc1cDZT3xFQXkdYwYkBGUYhMo2KKv18K9vdzMlJ5l5EzNDHtNrfmmEWhosCMLho88JrhWTtRYNhKKu0Ues28VjFx9jj1nFtgJXbV18bDZ3z2t9AUUgMZHGpQ4VpzXn4ToUnvD4/BSU13HW+AGcNX5gUEnGttK72hJz20uX7DBB6FL6XEjBuut+clFeq/vUe3xENWtL43IqspKjiTWF84rpg/n1GaM6fN5vdxwEIDGm5eTVhOwkpg5JYUpOSrvHsUT15FEZzBnbH19Afm2ozIubTjNKNnrbCH1YCyZEbwWha+lzgnvdrOHcOHsEj3+WF7JDAhhxXneEg7v/t4Gfv7wCMFKnvrz1FE4alQ5Av4Qonluyg/Oe+rpD560xe6Qdm5PccqOGuA7mwFpZEQVldWworLA93JtPG8mbP5veYv8rp+eYz2tdTtPj3QBtlqwUBOHQ6XOCC9jFx1sryl3v8eF2OSmqrLezGiysPNynP9/O/A377cUH7WFN1oUKGzxz+WQSolx8nVfS7nEsD/evn23jF/9eSazbyZ1njWH2mH4tKoL5/ZotRUY797bS12aOTOeE4WlBK+sEQTj89DnBfSN3L3+avwVovfbAYxcfw/mTs4hyOe3yjHkHqrjs70tZX1DBYxdNpKrBy66DtR3OUrBix9a5A/FrzTurC8krrm6xrTkxbhdzju5PdkoMXp8mJtLF1ScMYX9FPc8t2RG0b53Hx4XPfAMY7dLb4qWrp/Lmz47v0GsRBKFz9DnBXRGwpLc1r++0Mf04akAC7ggn9WYebkWdly/zSqis9wZ1/O1oHq61X6iJrfs+2ARATUP7WQqZSdE8fflkjs1JxufXNHh9bC2q4p3VBTy9eHvQvtYXyu/PGsOpR/Vr9Zgvf7ubEx76TArcCEIXc0iCq5TapZRap5RarZTKNcdSlFILlFLbzP+TzXGllHpcKZWnlFqrlJoUcJwrzf23KaWuPLSX1DaWpwmh45oen59FWw5QUF5nLHww97dWiDkUfGNOgEHHBTfbTAcLlQf84bp9QHh5uE6HA5/W5JfVcfqjS1iytbjFpJkVMonsQD3cwop6Hl2wtcW23F2lHH3nx5SZ9X8FQeg8h8PDnaW1nqi1nmL+fhuwUGs9Alho/g5wJjDC/LkWeAoMgQbuAo4DpgJ3WSLdFTR4/eSkxrDh7jNIi2uZMVBZ5+Gqfy5n4aYiRvaL57ghRuaA5Zg6lOLS55YCRiv108b0C7lctznzJmYydUiKPXlm4fdrW4Q7koe7ak8ZE+/5hOW7SvH5te0xR7ocQRkL0OTB//7dDTzw0aZWj2nt9+G6/S22PbtkBzWNPjbuq2zXNkEQ2qYrQgrzgBfNxy8CZweMv6QNvgWSlFIDgDOABVrrUq11GbAAmNMFdgGGRxoX5SLW7UKplp6fJX5ul4NLjxvE3688Fmha+BD4lHMnZfLUZZNDHicUsZHOFqJa52n6PcLV/p+j0eunvNbDBZOzeODccXbYINLlaOHhBsaorSXKobD284aYRDxmkPHdN2lQl30HCkKf4VAFVwOfKKVWKKWuNcf6aa33mY/3A1bwMBMIXDuab461Nt4CpdS1SqlcpVRucXHnVkVFRzopqmzg3vc3UlzVsq+ZJbhWyUL7eRFORvePJzbShdOhuPS4QVw+LafD5733/Y0s2lLM5dMGB41bgnvPvKO5dU77xWMsj3ZidhJnHN2/ycN1OlrEh5NjI3n0IqNkY1tZCta2UCGWijoPEU5FVESfC/cLwmHnUD9FJ2itJ2GEC65TSs0M3KiNe+3Dlk+vtX5Waz1Faz0lPT29U8f426WTuPsHR/OPL3fafckCsbIS3C4Hb6/M5/gHFlJe28iE7CQ+vnEmE7KTcCpFYnQE/1tbyIS7P+FgGw0pLUprGslOieZCsz6thcfnJy3OTUJUx1KyrLzb/LI6vs4rsb3SW84YxfI7ZgftG+d2cc4xWfRPiGqzG4TVeidUPHpHcTUen+bzLbLsVxAOlUMSXK11gfn/AeC/GDHYIjNUgPm/1ZmwAAhUmyxzrLXxLsNltgwP5fXZIYUIJw1eP4UV9UG3/WAshX3q8+2s2VtORZ2nQ6lhjV4/jV4/u5rV1x2QGE3uHbPZUlTFQx9vbvc4lhf7nxX5/OiF5WSnxPDH88YzITuphWhXN3hZuuMgNY3eNj3ccydlccMpw3GHCGlcc8IQAHYdlEpignCodFpwlVKxSql46zFwOrAeeA+wMg2uBN41H78HXGFmK0wDKszQw3zgdKVUsjlZdro51iX84b0NPP+VUcYwlAgNTY/l5WuOY0JWki1A9R4/q/aUcc6TX7FlfxV/+P4YALs4eUcyFRq8PooqGzjl4c9DTrKtzS9n2c7Sdo+TkeDm3EmZZCS48fk1aXFuLjw2m+0Harj/g41Bx847UM1Fz37L0LRYpg9LbfO4N58+ihW/P63F+KTBRuy2ql5SxgThUDkUD7cf8KVSag2wDPhAa/0x8CBwmlJqGzDb/B3gQ2AHkAc8B/wCQGtdCtwLLDd/7jHHuoQl24rZst9YfeUNkRObEBXBCSPSSImNtOO4DV4fFXUeVu0pp7bRy8yRRjjDKkjTMcFtarcemBq2obCCH7+4nMLy+g5lKRw9MJFHLpzI4NRYfH5t2lXGl3klPPfFzqA4rlU/4ddnjOKCKdmtHZI73lnHnMeWhNz2pbn6zWo7JAhC5+l0tTCt9Q6gRRMtrfVB4NQQ4xq4rpVjPQ8831lbwqHR6yfW7aKs1hMyrllQXsfqPeWcODLNniiq9/jtojdKKT7bbERJrBbqHQkpTM1JYUNhJaU1jdQ0eG0x319Rz6ebDpCTGhN2PVyAFbtLufqFXGabCxu8fo3LnO+z7HIqhcfnt5c0N6e63svm/VVc98pKHr5gQtCE4V3vbgDEwxWEw0Gfm3pu8Po5cUQaOx+YG/I2O3dXKde9spIDlQ30T4jmzLH9iXO77LQwh2paGZaTFsu5kzI7NOF1w6kjuH3uUUDwijIrPpwa5+6Qh/vu6gJG/u4j9pg1HKx0L7f55RBYhNz6Qrn070u55sXcVo9pZSd8sHZfi/SxynrDs02Lb5mzvC6/gndXd2m4XRC+U/S9erhmYZrWcmeb0sIcDM+I46nLJgNN8VpHwPMmZCXa5Q87QqzpEdcEeLKWyA5Pj+tQu3KPz+jyMG/iQL43fgD15vPdpvcaGCaxMhgiXY42yzMGxrIDvXW/X1NZ5+GGU4Zz8+ktS1H+cf5mvthW0mphc0EQgulzHu7ApGh8fs1v317LuvyKFtsb7LSw4DzcxOgIJg9OJibSSVJMBBcfm83JozI6fN65f/mCf327m3vPHkuGWQ4RjGLnALfMGcU7180AjFKOK3aHDmP7TBEdlh7HrFEZds5dpDnBF1hycmxmIs9cPpkRGXFtZikEinSg4FY3evFrWvXgR/WLt79EBEFonz4nuB/fOJMrpg/m1WV7Q6Y6BXq4u0pqmHD3J3ywdh9Th6Tw1s+PZ2h6HE6lcDkVGwsrGfG7D/lsc1G7562o8zAgMZrLpw0mNa5JcKMjnAxKibHjwQC/fXsd5z31DUWVLfufWeJYWF7Hx+v32YJ9zQlD2PH/5pIUUOA8Iz6KM47uT2qcu816uCcMT2NomtEU0xMwoVdRa4QTnv9qJz9+cXmL5+0sqaGm0dehpc2CIPRBwQVw2bffLb2++gAP1x3hoKLOQ0WzGfqDNY28/O0eCivqjFv8DmYpKAUbCyuDCsFceGw2S34ziy+3lXDeU19TUedhq1nD9kBlywUVVthhybYSfvbySkb2i+dvlx7DgKRoHI7gMElheR2LNh/A6/O36eFefcIQbjtzNP0TooJWqaTHu3nnuhmMzUxkTbO7gXqPj4Xm5GFHS1QKQl+nTwluXaOPi575hk83Gh6px9vSM7tgSjZv/fx4IpyK1FjDEy2pbuDzLQc4/dHF7D5Yw/WzhgNNM/eNbXiPFg1eH+W1jcx9/As7yyGQ8loPK3aXUd3g5Qdm+ceDNS0Fd2S/eK6cPph4s0NEv0Q3Z40fyJb9lfz27XWU1zaJ+Zd5JVz1wnKOG5LKeZOy2rTv9KP78+3tpzLE9HTBWN48MTuJIWmxLdLC8svq7Mf1jSK4gtAR+pbgenws3VlKmSlKoTo+9EuIYvLgZJRSRLocJMdEcKCqnsp6L1uLjGWuE7KTgKZJsI56uMnm7X7gpNkzi7fzs3+tINo8Vm2Dl7MnZjIhKzFke/NpQ1O5e95Y4qIMwc0vq+PLbSVs3l/Fq8v2BKVvWVkKFx2bzdXmirFQnP3EV1zzQuiQwevL99j2B77OvWVGlsQlUwfZGRKCILRNn/qkWLVtY90uYiOdQRkHFst2lgalOmXER1Fc1RBUD/ej9UZtnugwBPeCyVmcMCINCE4L21JUxbqCCjuGW9voI9Ll4Lkrptj7B+LxGcLnNG1fsLGIy/6xlGpTaAPTwqwwgtfvD/J8m9Po9bOlqIqr/rmMTQFlGJftPMitb62zf6+qb/JyLQ/3xtkjWhT6AXjy8zw+Xr+vxbgg9GX6lOBawtg/IYoN98zhkqmDWuzz1op8HviwqabBDyYOZNrQ1IA8XMXbKw1BTo6J5IrpgxnRr+32NQD3nzOOH0wYiEMFt0qva/QRE+ls8nAbfdzzv412a5zmPP35dkbe8RGY3xVW3qyVpRCYWmYJ7v0fbGLOY1+0apvX76fe42fRlmIOVjcJc2WdYee4zESOH5YadOx808PdVVJjC3F1g5c9B2vx+vz88eMt/Ozlle1eF0HoS/RJwY1so+5svdcXdIt83azhXDVjCFb0IdArToyO4J55Yzm2nfbmWhuFwpVSxEa6qG4IzsONjnSSEhvJhKxE3BEOaht97DpYy63/WdviWFaWwqxRGbz5s+mkmkXUQwmutW90hDPkpNkjC7byz6924vHpgFVzTd53RZ0Hp0Nx1vgBvPKTaWQkNDWpPHtiJudPzuKiZ79la5HRi+2udzdw8p8XcVC6QwhCSPrUwgeHQ3H0wASSYyK5/pWVzB03gLnjBgTt0+DxE9UsB7fe4yMjwc3MkelERToYlBLD5MHJ5KTF4vH58fl1yNtqi5LqRo69/1PuPXssD5w3jsEpTRNTdR6fWWs3gXevP8E+HxjhBq110CINn1/jUEYGQXq8m1V7jB5t0RFOoiOcQVkG358wkHGZiczfsD+k4D6+cBsAWcnRdpv2xoCJxIo6DwlRoQu1HzUggQunZPOfFfm2vX6tyUyOpl9CFKeP6WevhhMEwaBPebjD0uP44JcnMmN4Ku+v3cfmEG1j6r2+oGLb//xqJ6N//zHjs5J46eqpZMRH4VBNsdKxd83n0U9b9gILxEqbcjsdnDV+IOOyEu1tg1Ni7Hq0FtZy36LKemb+aRH/+HKnvc3r17gcDgrK6/jPinw7BDB33AA23TuHkf2ajpWZFM2M4Wm4XY6QebgnjkhjYnYSF0zO5rQxRi2GVXvLePnb3dR7jII9CdER7Cyp4aQ/LWJRQHbFwk1FlJpZFFYucGlNI8kxkVTVe5gxPI0ThreMQQtCX6ZPCa6FUooIp8ITYiltg8cftMosJda4ZQ/sDrHrYC3vri6kusFLrNtlT1i1hr16LcLB1qIqVu8tt7f96YIJ3DNvLDUNXs78yxe8kbvXFrB9FfXsLa3j8y1NQufz+3E6FOsLKvj1m2uYmJ3EP686lsgQhWk2FFbw4bp9RDgdIXOOYyNd1DZ6+dXsEVx0bDZD02JZuqOUO95Zj1Jw5/fH8MJVU3E5FLsP1lJsFlrXWvOTl3J5Z1UhALXm6yurbWRtfgXj/vAJe0prueOsMdQ1+rjh1VUdKj0pCN91+pTgLttZyvf/+iVbi6oMEQpxm/3whRN4+MKmImjp5jLcv3+xgxkPfkZxVQMXTjFyWn0+Tazb2aIxZHOs1WuRTgcPfrSZ3/13XYt93C4Hm/ZVsq+8np+eNNQuAQnwxbYSO0vi+GFpXDtzqF0tLDM5mlmjMthSVMWvXltl13wAeHd1ITe9sZoTR6Rz4+zgmg9aaz7esJ+tRdXUNnrplxDFZ78+mQmm9601pMW5GZIWay/ttVLO6j1+/LqpoI1Vz6EsIBOi1lyBtqWoiv+tKeTCZ74J6pgsCH2RPiW4+yrqWFdQgUMpXA4V8jZ7YFK03dIcsOse7CipoaC8Do1mWLqRleByWpNgbQtJUxcJB4nREUEr1+b97Ute+GonLqeDqAgH1Q0e5k3M5OcnDQs6Ro0parNGZ/B/p420V5Vt2lfJJxv2U1zVwLurC4Pa/TR6jZKM04elcp25WKO5TQCT7/2UP5rdJj7farTS+Wb7Qf71zS4Wby22c36txQ9VDcb/OamxPPXDSRw/3Ki6NnZgIiMyjGvzZV4xI+/4iI2FRtjmofPG4XY50Vrz76W720xT6wy/fXstObd9YFc3E4TeSJ8SXEswEqMjGJAYHVS/wOL15XtYvLWpf1d6vDEzb9U1cCjF/9Yat9IupyLO7WrXw02NjeTamUMZnBpLQpTLtsPr87Mmv4IKM/0qzh1BdYOPTfsqGZ4Rx+iA2K61HLi6wUtFrcfOw30zN58bXl1le7y+ZtXCIpwOqhu87C2tDSpsY2VK3DPvaLx+Px6f5sKnv2H3QWOiq7Lew2OfbmP+hv04HYrYSKft4Vp5xGlxbs4cN4CsZOML6qnLJvPhr07kd3OP4oZZI/D4NNsOGMuULY89v6yO3/13PQ9/0nbcO1xeXWb0IbXqP3SWTzcWUVBe1/6OgtAJ+pbgmoIRH+Vi/v/N5DchuuQ+vjCP91YX2r8nRLn46UlDGTvQuNV2KMX6AsNri3A4OH9yFvPMpbitkZ0Sw+1zj2JYehyJ0RFUNXjx+7UtevGmBxnndlLd4GXe377iH1/u5LQx/ThzbH/AWPoLcO//NnLGY0tsgW30+XE5lO3xBnd80LgciteX7+XEPy6iKuCLwfqSiI104fFpIpyKZbua4qxWDYnEaCOccMbY/gw3vVcrZh3rdrFkazF5pqgCRDgd/GTmUAYkGV9UeQeMlLGv8g5yysOfkxbnxulQ9nEPN4dSKH1HcTU/fimXm99YLQV5hC6hbwlunQe3y9FmCldDszxcpRS3zRlNUWU9kU5HUKNFh0Nx8dRBXBxiAUUgjV4/VfUe/H5NQnQEWhvCYImDdcs+fVgqQ1JjaPT5iYl0cvPpo+wmjqXmLbjXr3E6FOOzk/jwlycyun88TofCaQlu0EozTYTTQYSzZdNMS+xvfnMN0NQu6NLjjNeyv6Ier1/bwvjIhRPtbTlpMfzrmqlMGpTEtf/K5c3cfLYVVTHjwc/4Yptxd5AUbcR3Lz52EF/ddgoRTsWO4hp2l9aQGhsZskX94eBQQgpWr7tvd5TyxbaSw2WSINj0KcEdkBjFieZy2dv/u44nFuW12Kc+RB6uUoofThvEEz+cRKzbxdEDE5h9lFELt67Rx4EQZRQDWbCxiHF/+IRtB6o54+j+vHj1VKIiHbbgJpiC+8C54/nJzKFAU/ueMQMT+OCXJzDFbObo8/vtUMaYgQm4XU5c5heB5T1a3Dh7BM9eMdlurRPYUijeHexhRkU4cSgj/BEV4WCvuXQ3lCcaHxXBiSPSSY1zEx3hpM7jo7i6gYLyOvv81vNqG71kJkUzONXIPb7gqW84UNVgZzwcCntLaxl++4dsLKzEShU+FA93YFI0V83IYUhaLC9+veuQ7ROE5vSphQ8/mjGEH80wPMbcXaWUpcexv6Ke/olNK6iae7gW5xzTVG1LKaMZJBhdD97MzWf93We0el5rdt7tcpCdEmNPykU4FTOGpzIgMdre18rBtbzwmEgXRw9sytu1PNyS6gY+XLePXQdrDI83K4ncO2YHndc6jzVxFejhDkqN4fFLjuGXr65i7rj+TMlJxq/hr5/lce6kTMZnJvK/NYV2hsKNr62isLyeN342nV0lNWworOSU0RmG4Db67JCHVaAnNS6SHx43iEVbDuCOcDLT/KKzwhqHw8PdWlSF16/5dFMREU4HjV5/m6sI2+MXJxsTi3eepVvtCCIIh0Kf8nADcTkcrNlbzrQHFvLckh2AEf/0+HQLD7c56wsq7RKL8W4XNY3eNmN+gVkKFXUePl6/j6LKekb0i+ffP55mVx+7/4ONzP2LUfMgOiDs8crSPXy74yDQFJctLK/jznc3cPKoDJ69fHLI836+5QAfr99vi1Bg3VqfX9vVzq6dOYxjc1IYYH7xTB+ayuXTc1hxx2xOGW148j4NB6oMT/6LbcVc98pKqho8REUaHm6pOaln5S3Hul3cf844NhRWsnBTEUkxkbYnPzUnhYfOG9/mNQbjfDe9sTqo9kQg1hdRalwkK39/GmvuOp2TAtLpwqGy3mPnP4vYCl1FnxLcq19YbufARjgVQ9PjGJgYxSMLtlJR68GhYNntp3LVCTltHifwQx3rdqE1bTaAtGo4uF1OCsvr+NnLK1m5u6zFfjWNPirrvTxy4YSg+gx/nL+ZD9YalbfOPmYgV88YYt+6ZyVHc8ygZPLLavnxi8vJDZj4euHrXTz5eR7jMhO5+wdHkxrb1A3ijdy9dmPJXSU11Ht8PPHDSYCxiq6grM4IGZiinBDlsm/XrTS4eHcE0RFO6j0+O80rKaYpBOH1+dlTWku62eFishkW+f6EAYwZmNDq9bJ4eP5W3l5ZwPtrQ1cds+LpFXUe4tyuQ5qIe3TBVo69/1MAFm8t5qf/ym03+0QQwqVPCe6O4mp7sijC6cCvNc9dOYUGr49nlmxHKUVGQlS7XXj7JbjpbxZyiTVrELT14QwMKViiUFHn4c3cvZz4x89ssYp3u1DAuZOyGJTalAucHBNpLyqYM3YAF08dZAvuZ5sOsHhrMbWNPj7ddID9AfFkyxsemh7HlcfnBLXfsewdkRHHja+v5r3VhXbq2YMfbWbmnxbx5/lb7Emo+KgIquoNT766wfhyiopwcN/ZY7n59FEMSo3le+MHBK3Sm/HQZ2jdtHjkmhOGmtfByevL97TquVposzJEqHb2AK+atXr3V9Rz/wcbybntA55evL3NY7bG/op6+iW4zcd1zN9QRHmd5PQKh5c+JbhGMRZD8LJTYli2s5TcXWWM7p/Alv1VVNR5eGTBVjvm2RrvrCq0hc0q+lLdhuBOHpzMjbNH4HY5SDAFt7Lew4GqBvaW1tnx2li3iwavn6/zSoKOlxwTYcdIN++vpKbBa6eFvZ67lycX5TVlKTQrz+hyOqhp8LJ5f2WQwFnHt7oSR7iU7fFaXR/+tijPzt2Nj3LR6PPT4PVT0+Ajzm0UtTlmUDJHDUjgBxMG8sSlk4Jet+XZW4KbHu/mqhk51DZ6ufWtdRSUtZ3vOsOsxeByhL7Ft3Juxw5M5LkvjAyDncUt+9R1hP2V9XYs3XqPHGpOryA0p88IrtaaynovCdGGQD560URmDE/jPyvy6ZfgpqiqntKaRh5fuI0tRW0LbmAsdGxmIrfPHR3kPTZn8uAUbpw9EpfTQWykE6dDUVHnoareS4RT2bfGlnhf+vel7Ciutp+fHBNJaU0jtY1e5jz2BS98vSuoTGRGQpS9EKJ5ecYIp2LVnnLmPPaFnT8MhocbHeG0Y8+B3SVyAtrsxJviMy4zkYumZOPza6rqvbatK3aXsXBT6Caali2W4I7qH89d3z+aUf2NcEJ7E2c/mDCQnQ/M5cJjs+0xv18z/g/zeW7JDirqPGTEu4MKtVur4MLF8HCNu5bEgC9FQTic9JkshdpGHz6/DgoX5JfVMiIjnt9/fwyRToc9KdTepFkgwzPi7AUBzdFac8Orq4iNdPHL2SPITIpGKUVClMte3hsfFWFP0gQWMg+cNEuKiWTTvkrbI8xKjiYrOYbFt5zMSX/6nH7x7lY93Pgol52H6w3Kw/WhFJz26BLACLGM7h9PUkyEHS6Jj3LZx505Mt1eLfZ/p43gqhk5ALz49S7WFVTw9OLt9EuI4m8BXu6s0Rnk7ipj+tDUoOtiCXB7qWE1jT7crqY8YjDqNVTWe1lXUEGj109CdESQcHcmLczn1xyoarAnDRMCwj6CcDjpMx6u16+ZO66/Xb7w4U+2sL24hszkaDKTokmPd7Ov3BDcwDSxUEwbmsLUIcakVqPXz47i6pDe0LqCCt5fu4/Xc/cy48HP7PHnf3QsPztpWJCnCHDiiHT+eL4xex8d2DZ97mj+d8MJ5JtLTjOToo1+a+YkWL+EKNwuB4NTY+wFDABP/nAS958zzu5SbKWcAcwYnsqPTxxq/2552m6X0/bwIppVINNa4/drspJjGJtpZAhYaWFFlQ1BOcAASdERVDd47fNbWJNo7Xm4P395BSN+9xFPfd4Ul7VE+r01hVTUecg7UM28J76ytzdvdtkRvH4/t889illmRkZSTAQD23kPCEJn6DOCmxgdwZM/nGx/qJabs/mZSdHkHajiL59uY12B0Qrcqg3QGgpl34rvLavllIcX89mmlp1431tdSIRT8ehFE7h33tH2+DGDkg3RGpjIqeYCCgurmHegh5sW5yY1zm17uJnJ0dQ0eLn7vY0AZCS4yUiIYvEts/je+KaC6lnJMWQmNRUXv+bFXB7+ZAsAZ40fyE2nNVUQG54Rx5r8ChZvLeakUYYnmxKQ1bBidxnDbv+Qr7aX8MHaffaKsuhIYzny/op62zO2yEyOtlPPAkmIdhHpdLTr4VoThYHlKUuqmorenD85uBPx9KGpHcp+aI7b5eSaE4bYWRRZyTF8/dtTOePo/vY+WmsWbCwKuoMQhHDpMyGF5pTVGJ5QVnI0u0pqefTTrRw/LJXoCCdpca3HYwG+MXNiIXjSrHl3hhH94rh6xpCgRRMAX28vobzWY68qs1hfUMGd724Agj3cvANVvLu6kPyyOlwORUZ8FAdrGnhrZT5XzxjCyaOCRdvitWV76J8YxUkj03n28snsLavjArO0ZFW9B7fLSWpsJHPG9mdwaiy/PXM0jV4/o/snsPOBuUEVxWLdTvzmkuTHPt3KiH5xnDginagIpz0BN6xZaOWqGUO4YHI2zVFK8d4NM1oIdHOsv1Fgy57i6qYsjO+NH8C6ggreWpHPqjtPQynVwsvuCAerGyiv8zA4JaaFN27x3ppCfvXaav7w/TH24hlBCJc+I7ifbS7ipjfW8Nq10xjdP4FxWYmU1TYya3SG3an2R8fn8PTlqe0mvn9600l2xwcrLWzx1mLufX8jr/zkOHx+GJgUxUXHhq6x8O+le9i0r7JFex9rgcJZ4wcExZHdLid//SyPsycO5KHzxuN0KHuSa1BKtFEQp97DT17K5crpOZxpHvevn+Vx3NAUTh6VwekB3hrAxc9+S7+EKJRSbCispN7j46dmScjaRi9b9lcxJC3WzqCIt2vieozC62boItATbx7LjnA2hT2aM7p/+56olS4XWHJyYMCqvFV7yolwKqoavEFiuy6/ghi30y6j2R7/W1PIH/63kdw7ZpNmhjuue2Ulx2Qn2WEXa1HE3nYyKwShLfpMSKGsxkN5rccWiAinQmOIgjU7faCqod0cXDCExYoFx0Q4Ucqotdvg9XPtSyu44vml/G9N6y3CE6MjqKzzMPuRxfzhvQ32uOUtnzgiza7+BUYK25gBCeSX1XGeeRttZSU898VO/H6NXxtFV6zSgl6fn8p6T1ChHr9f8+Tneby/tpAas1vFwKQoVu8tZ/P+popfeQeqOefJr7n7fxvtMauiWVW9l+oGr11w56Jjs3ng3HFcMjW71cnDUKzYXRqyloVlZ2lNIzWNPlwORVmtx57wO25oKn+/YgoAlzz3LW+ZHZR/+doqnv9yJ9MfWMj3//Ylpz68uMO27KusJ8KpSAnINFmzt5wNAemBF07JJtLpwOWUVWhC5+kzgmtNalmCWtfosydtUmMjcSi44531raY4tYbDYRQhn5qTyis/Po6DNY0MTIy2b91DkRHvprSmMSj1C5q85QUbW8aD54ztT+7uMtaY7Xmc5ge/oLwOh0O1qIf7ZV4JVfVeu4aBZeu7qwp5Zekeqht8xLmddmHywFxX6xoFVsyKi3ShlDFzX93QNNnXPzGKS6YO4oFzx3foy8pi6c5S/hSwsCKQ2Y8s5va31/Hr00dy7qRMspKjA7pN+DhmUBIPX2B05Th5VDouh+KDtfvwa82+iqaQQ0frNewrrzd61TW7BoETcA6HYkBSVLu5w4LQFn1HcOuCa8/e/YOxLLz5JABcToc9I7+jE4nzd31/DKcelcHxw9P4z8+m8+bPptu3pqE4YXgafm0UwAnMUrAefxpC9E8/2mjyaHXadTYLezQvz/jOqgISoyPsSUKLk0els3xXKSXVDWYtXMNzDMxIsIQ/MJbtcCh+cuJQRvWPRwfYvftgDY98siXsDg6jzDuEbUVVQeNb9lexo6SGLUVVXH/KCP54/gS+vPUUOzTx4xdz+fnLK+36EyeNTOfHJw4l0ukIuuZREQ67aHx7rNpb1mKyrXlnjtveWktSTGSLzhmCEA59R3DrjfX21qRIYkxEUIzvnz86FoDslOiQz2+LWaMzuPwfS3l9+R6m5KSQ2obYAkzMTrJzS60vAKDNCZ9R/eL50/njuf+ccYAhKEPSYploCo/1XL/fSN3aUVLTYqktGBNNVmuhuCgX17+yCiAo1zU93s2dZ43h71dOCXru7XOPYu7YASy+5WQumGJMhq0rqODxz/L4+csr23zNzbFCMlv2B3v5VkbCzpIa8stqW/SdK65qIDEmgjdXGB0e4qNc7CypxuFoupb/N3skm+6ZY6eutUV+WS17S+s4flhwrnBidESQ9/1lXglDUmM4akD4WRCCYNFnBHdcZmKLNKJArA9XeylhoXh/TSF+DYNSYtvfGcOjfu3a6UBT8XGLU0ZnMC6EUCiluGBKtp0jrJTC6/eTY9ZccCrFmAEJpMS6jdDBdTO486wxLY4zLjORQWbZxuOHNYUbmufcXn3CkBbXosHro6bRy+DUWDtlzLrVtzo8dJTMJCNlbGszDzewCeYJDy3iq+0HueL5ZSwyhbi4uoH0eDfPLDYqvB2sbmT+hiLqPX57Ym/S4CSUUtR7fEElKUORGuvmuSumBKWAgRGnzzZfv9fnt0MV76wqaPeYgtAafUZwzz4mkz/84OhWt//zq10A9ocsHP5gTi6FkwM6ODWGi4/Ntm+tLWobvUHeZlvsLa2j3mN8+B0OxYe/OpGU2Ei2F1ejlArZ2UIpxUXHZnPSyHQmZicxw2wA2Vo2QSCX/30ZP/jbVzy9eDt7S43eZ1Zq16xWUtNaw+FQjOgXzx7zOBbNQzoZ8W6WbC1m+4FqPD4/ZbWNpMe57bbw47OS7H1T4yJxuxw4HYqNhZUcc88CFm8ppi2iI52cNqYfA5OC72x+fcYo/mHe9eyvrMfn1+wureXG11ezv6JjoQpBaE6fSQtrjwunZFPv8ZEYE36JP6WMtuLhlAdMi3PzYIiasN/uKA2xd2ievmySHcsEYyLwlv+sYfZR/Xj0oomtPu8XJw+zY5HjMpNYvrMsKJbcGvFRLpbtKuXBjzYzISuJ7JQYZo3O4NObTgorQ8HiX9dMtc9bWtOIx+dnR0kNZxzdjyVbS6jz+BicGkOky8GugzWU1jTa1ceOGZSE1sYXF8AtZ4xiWHocL//4OCYNSsbnNyqlLdhYxOwx/YLO6/H52bK/ivUFFWwpquKyaYPbTCGzJsqm5qSwak85heV1QZ2dBaGj9BrBVUrNAf4COIG/a60f7M7znzc5y065CpcvfjOrzXq44fD5r08mooNdC+aMDc7jPerOjwEjVastAvOM6z0+Gn1+6j2+Nnu9ARw1IIGFZuH1gQEhhM6ILTTl9hZXNXD+019zoLKBOo+PYwYlMzjVaHMTE+nie+MG8NaKAn50fA7XzxrOxOwk3lqZz6o95URFOHG7HPYEl1VH2OlQnDQqnYWbi/D7NQ6HYmdJDX+ev4UlW4vtzhPxUS5mDEtrIbjzN+znL59uMycJNROzk5g2LJVnluygsEIyFYTO0SsEVynlBJ4ATgPygeVKqfe01hvbfmbvoDNx39YIrNTVWY4bktL+TibThqawYGNRh1Zo3Xz6SH5y4lAafX67AM2h8szi7fxp/ha8fk2c28UTl07ihBFp/PrNNfZKt+tmDefd1QW8t2Yfvz5jFBCcxtbg9fNm7l5un3tU0LFPG9OP99fu49kvdnDtiUOJiXSSu7uU740fwPHD0xhvxrMdIV57vcfHxn2VbNxXyVnjB/DOdTPsxQ+Wx1vv8eHXOqh+RU9j5Vd3hl0lNTiUCqrF3JuxvkiPJHrLO2UqkKe13gGglHoNmAccEYLbW7hgchbThra/Ui6QOWMHtPCUW0Mp1amQS1tMyUlBKbjmhCH8avYIO5d3ak4KmWZcdXhGHOdNyiI7uSnO+tLVx1FlTnQ+cuGEkLf4p4zOYFS/eF5fvpefnTSMfglRfPvbUzt0fazebJceN4j75o0FjHhvdITT/pC/u7qAW99aR5zbZXe6qKzz8NGNM8lMiuaN3L08vnAbWpuFf7TRTePTm08iISqCxz7dygtf78LvN5aEG1k0ioU3nYTL6eDP87fw31UFQXZFRThYePPJgNEIdcHGIiKdDhp9fiKdDlJiI3nnuhnsq6jj4me/RZvn9Jvn/80Zo7hgSjZb9ldx8bPf4HQoHMpYBFRc1cBLV09lUGoMi7Yc4M5317e4Lv+48lhG9ovnnVUF/Gn+lhbbX7t2GtkpMfx76W6eXNRUdEgp4+edX8wgNc7NP77cyUvf7Grx/I9/NZPoSCdPLMrjzdy9QdscSvHZr43Xfut/1vLGir2kxETa5U0ToiP4+MaZAPz27bV8bsbvre5X/ROjeOe6GQDc8Ooqlu08GHT8YelxvPKTaQD8+MXlJMdE8icz3/tw0VsENxMIvLr5wHHNd1JKXQtcCzBoUNutyfsih/vN0R1MHpzM0ttnkxwTESSEzetMPHDuOLwBhWOiI512vYlzJ4UOBcVHRfDxjSdSUt2UI9zRL6Ppw1J58oeTmH1UvyAv6tGLJtjZKOOzkrh1zmiKKuupqPOgIKgcptvlYOqQFBQKhzIEQ6km7/yoAQnMmzAQpYxiSFUNXnz+pnocQ9JizS9QQzQ0moiAusXHZCehtabBa4htg9fPyH7x+PyaqAgnU4ek4FCB51b23VhCtIuzxg/EZ1aA8/k1o/rHM8ks4ON2OTh2cMs7JWulZka8m2nNym5CU/PTgUnRTB+Wattt/rPTMgckRnFMwPxD098He/uEENstZo3OID3ezcGaRjt1MCag/shRAxKCCg0pFEmxTc7ChKzEFoWV+gXU9pg0OJn4Tt4ptIVqq/lhd6GUOh+Yo7X+sfn75cBxWuvrW3vOlClTdG5ubneZKAiC0CGUUiu01lNCbestaWEFQOBMT5Y5JgiC8J2htwjucmCEUmqIUioSuBh4r4dtEgRBOKz0ihiu1tqrlLoemI+RFva81npDO08TBEE4ougVggugtf4Q+LCn7RAEQegqektIQRAE4TuPCK4gCEI3IYIrCILQTYjgCoIgdBO9YuFDZ1BKFQO7w3hKGlDS7l5dT2+wozfYAGJHb7MBxI7mdMaOwVrr9FAbjljBDRelVG5rqz/6mh29wQaxo/fZIHZ0vR0SUhAEQegmRHAFQRC6ib4kuM/2tAEmvcGO3mADiB2B9AYbQOxozmG1o8/EcAVBEHqavuThCoIg9CgiuIIgCN3Ed15wlVJzlFJblFJ5SqnbuvG82UqpRUqpjUqpDUqpX5njf1BKFSilVps/c7vBll1KqXXm+XLNsRSl1AKl1Dbz/+QuPP+ogNe7WilVqZS6sTuuhVLqeaXUAaXU+oCxkK9dGTxuvlfWKqUmdbEdf1JKbTbP9V+lVJI5nqOUqgu4Lk93sR2t/h2UUr81r8cWpdQZXWzH6wE27FJKrTbHu+R6tPEZ7br3h9b6O/uDUepxOzAUiATWAGO66dwDgEnm43hgKzAG+APw626+DruAtGZjfwRuMx/fBjzUjX+T/cDg7rgWwExgErC+vdcOzAU+AhQwDVjaxXacDrjMxw8F2JETuF83XI+Qfwfz/boGcANDzM+Ss6vsaLb9YeDOrrwebXxGu+z98V33cO3mlFrrRsBqTtnlaK33aa1Xmo+rgE0Yvdt6C/OAF83HLwJnd9N5TwW2a63DWSXYabTWS4DSZsOtvfZ5wEva4FsgSSnVsQ6bnbBDa/2J1tpr/votRqeTLqWV69Ea84DXtNYNWuudQB7GZ6pL7VBGU7cLgVcPx7nasKG1z2iXvT++64Ibqjllt4ueUioHOAZYag5db96SPN+Vt/IBaOATpdQKZTTiBOintd5nPt4P9OsGO8Do5hH4QeruawGtv/aefL9cjeE9WQxRSq1SSi1WSp3YDecP9XfoqetxIlCktd4WMNal16PZZ7TL3h/fdcHtcZRSccBbwI1a60rgKWAYMBHYh3Hr1NWcoLWeBJwJXKeUmhm4URv3S12eH6iM9kk/AN40h3riWgTRXa+9LZRSvwO8wL/NoX3AIK31McBNwCtKqYQuNKHH/w7NuITgL+UuvR4hPqM2h/v98V0X3B5tTqmUisD4Q/5ba/02gNa6SGvt01r7gec4TLdobaG1LjD/PwD81zxnkXU7ZP5/oKvtwBD8lVrrItOebr8WJq299m5/vyilfgScBfzQ/HBj3sIfNB+vwIidjuwqG9r4O/TE9XAB5wKvB9jXZdcj1GeULnx/fNcFt8eaU5pxqH8Am7TWjwSMB8Z8zgHWN3/uYbYjVikVbz3GmKhZj3EdrjR3uxJ4tyvtMAnyXLr7WgTQ2mt/D7jCnI2eBlQE3FoedpRSc4DfAD/QWtcGjKcrpZzm46HACGBHF9rR2t/hPeBipZRbKTXEtGNZV9lhMhvYrLXOD7CvS65Ha59RuvL9cbhn/nrbD8bM4laMb8XfdeN5T8C4FVkLrDZ/5gL/AtaZ4+8BA7rYjqEYM81rgA3WNQBSgYXANuBTIKWL7YgFDgKJAWNdfi0wBH4f4MGIuV3T2mvHmH1+wnyvrAOmdLEdeRgxQev98bS573nm32o1sBL4fhfb0erfAfideT22AGd2pR3m+AvAz5rt2yXXo43PaJe9P2RpryAIQjfxXQ8pCIIg9BpEcAVBELoJEVxBEIRuQgRXEAShmxDBFQRB6CZEcIXvNEqpe5RSsw/DcaoPhz1C30bSwgShAyilqrXWcT1th3BkIx6ucMShlLpMKbXMrI36jFLKqZSqVko9atY1XaiUSjf3fUEpdb75+EGz9ulapdSfzbEcpdRn5thCpdQgc3yIUuobZdQRvq/Z+W9RSi03n3O3ORarlPpAKbVGKbVeKXVR914V4UhABFc4olBKHQVcBMzQWk8EfMAPMVay5WqtjwYWA3c1e14qxrLVo7XW4wFLRP8KvGiO/Rt43Bz/C/CU1nocxooo6zinYywtnYpR7GWyWQxoDlCotZ6gtR4LfHyYX7rwHUAEVzjSOBWYDCxXRkeAUzGWL/tpKnjyMsayzUAqgHrgH0qpcwGrdsF04BXz8b8CnjeDproP/wo4zunmzyqMZaajMQR4HXCaUuohpdSJWuuKQ3uZwncRV08bIAhhojA80t8GDSr1+2b7BU1OaK29SqmpGAJ9PnA9cEo75wo1waGAB7TWz7TYYLRcmQvcp5RaqLW+p53jC30M8XCFI42FwPlKqQyw+08Nxngvn2/ucynwZeCTzJqniVrrD4H/AyaYm77GqCIHRmjiC/PxV83GLeYDV5vHQymVqZTKUEoNBGq11i8Df8JoHyMIQYiHKxxRaK03KqXuwOhg4cCoNnUdUANMNbcdwIjzBhIPvKuUisLwUm8yx28A/qmUugUoBq4yx3+FUej6VgJKV2qtPzHjyN8Y1f2oBi4DhgN/Ukr5TZt+fnhfufBdQNLChO8EkrYlHAlISEEQBKGbEA9XEAShmxAPVxAEoZsQwRUEQegmRHAFQRC6CRFcQRCEbkIEVxAEoZv4/27OA1chYzgpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1296x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import colors\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import random\n",
    "from numpy.random import rand, seed, randint, choice\n",
    "from random import choices, sample\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "env = Env()\n",
    "env.reset()\n",
    "\n",
    "rows = 35\n",
    "cols = 35\n",
    "\n",
    "obstacles = [\n",
    "    *list(range(0, 2+(rows-1)*cols, cols)),\n",
    "    *list(range(1, 2+(rows-1)*cols, cols)),\n",
    "    *list(range(34, -2+(rows+1)*cols, cols)),\n",
    "    *list(range(33, -2+(rows+1)*cols, cols)),\n",
    "    *list(range(0, 34)),\n",
    "    *list(range(35, 69)),\n",
    "    *list(range(1190, 1224)),\n",
    "    *list(range(1155, 1189)),\n",
    "    *list(range(630, 639)),\n",
    "    *list(range(665, 674)),\n",
    "    *list(range(700, 709)),\n",
    "    *list(range(1028, 1039)),\n",
    "    *list(range(993, 1004)),\n",
    "    *list(range(958, 969)),\n",
    "    *list(range(574, 583)),\n",
    "    *list(range(539, 548)),\n",
    "    *list(range(504, 513)),\n",
    "    *list(range(251, 260)),\n",
    "    *list(range(286, 295)),\n",
    "    *list(range(321, 330)),\n",
    "    *list(range(271, 279)),\n",
    "    *list(range(306, 314)),\n",
    "    *list(range(341, 349)),\n",
    "    *list(range(880, 2+(rows-1)*cols, cols)),\n",
    "    *list(range(881, 2+(rows-1)*cols, cols)),\n",
    "    *list(range(882, 2+(rows-1)*cols, cols)),\n",
    "    *list(range(727, 1077, cols)),\n",
    "    *list(range(728, 1078, cols)),\n",
    "    *list(range(729, 1079, cols)),\n",
    "    *list(range(20, 300, cols)),\n",
    "    *list(range(19, 299, cols)),\n",
    "    *list(range(18, 298, cols))\n",
    "]\n",
    "\n",
    "class Grid:\n",
    "    def __init__(self, gridsize=[35,35], nA=4, s0=720, goals=[1052, 134], Vstar=None):\n",
    "        self.rows = gridsize[0]\n",
    "        self.cols = gridsize[1]\n",
    "        self.nS = self.cols*self.rows # we assume cells IDs go left to right and top down\n",
    "        self.goals = [self.nS-1, self.nS-1] if goals is None else ([goals[0], goals[0]] if len(goals)==1 else goals)\n",
    "        self.Vstar = Vstar # optimal state value, needed for some of the environments\n",
    "        self.s0 = s0\n",
    "        self.s = s0\n",
    "        self.trace = [self.s0]\n",
    "        \n",
    "        # actions ---------------------------------------------------------------------       \n",
    "        cols = self.cols\n",
    "        self.actions_2 = [-1, +1]\n",
    "        self.actions_4 = [-1, +1, -cols, +cols]     # left, right, down and up\n",
    "        self.actions_8 = [-1, +1, -cols, +cols, -1-cols, -1+cols, 1-cols, 1+cols] # left-down, left-up, right-down, right-up\n",
    " \n",
    "        self.nA = nA\n",
    "        if nA==2: self.actions = self.actions_2\n",
    "        if nA==4: self.actions = self.actions_4\n",
    "        if nA==8: self.actions = self.actions_8\n",
    "        \n",
    "        # rewards types-----------------------------------------------------------------\n",
    "        self.nR = 4\n",
    "        self.rewards = [0, 1, 0, -100] # intermediate, goal1, goal2, cliff\n",
    "        self.obstacles, self.cliffs = [], [] # lists that will be checked when doing actions\n",
    "        \n",
    "        \n",
    "    def reset(self, withtrace=True):\n",
    "        self.s = self.s0\n",
    "        if withtrace: self.trace = [self.s0]\n",
    "        return self.s_()\n",
    "    #-----------------------------------------rewards related-------------------------------------------\n",
    "    def rewards_set(self):\n",
    "        return np.array(list(set(self.rewards)))\n",
    "        \n",
    "    def reward(self):\n",
    "        stype = self.stype()\n",
    "        reward = self.rewards[stype]\n",
    "        if stype==3: self.reset(False)    # s in cliffs\n",
    "        return reward, 2>=stype>=1        # either at goal1 or goal2\n",
    "    \n",
    "    #-----------------------------------------actions related-------------------------------------------\n",
    "    def invalid(self, s,a):\n",
    "        cols = self.cols\n",
    "        # invalid moves are \n",
    "        # 1. off grid boundaries\n",
    "        # 2. off the right edge (last and is for right up and down diagonal actions)\n",
    "        # 3. off the left edge  (last and is for left  up and down diagonal actions)\n",
    "        # 4. into an obstacle\n",
    "        return      not(0<=(s+a)<self.nS) \\\n",
    "                    or (s%cols!=0 and (s+a)%cols==0 and (a==1 or a==cols+1 or a==-cols+1))  \\\n",
    "                    or (s%cols==0 and (s+a)%cols!=0 and (a==-1 or a==cols-1 or a==-cols-1)) \\\n",
    "                    or (s+a) in self.obstacles\n",
    "\n",
    "    def step(self, a, *args):\n",
    "        a = self.actions[a]\n",
    "        if not self.invalid(self.s,a): self.s += a\n",
    "        \n",
    "        self.trace.append(self.s)\n",
    "        reward, done = self.reward()       # must be done in this order for the cliff reset to work properly\n",
    "        return self.s_(), reward, done, {} # empty dict for compatibility\n",
    "    \n",
    "    #-----------------------------------------state related-------------------------------------------\n",
    "    # useful for inheritance, observation can be a state (index) or a state representation (vector or image)\n",
    "    def s_(self):\n",
    "        return self.s\n",
    "    \n",
    "    # returns the number of states that are available for the agent to occupy\n",
    "    def nS_available(self):\n",
    "        return self.nS - len(self.obstacles)\n",
    "    \n",
    "    #-----------------------------------------goals related-------------------------------------------\n",
    "    # returns the type of the current state (0: intermediate, 1 or 2 at goal1 or goal2, 3:off cliff)\n",
    "    def stype(self):\n",
    "        s, goals, cliffs = self.s, self.goals, self.cliffs\n",
    "        # the order is significant and must not be changed\n",
    "        return [s not in goals+cliffs, s==goals[0], s==goals[1], s in cliffs].index(True)\n",
    "    \n",
    "    def isatgoal(self):\n",
    "        return self.stype() in [1,2] # either at goal1 or goal2\n",
    "\n",
    "class Grid(Grid):\n",
    "    def __init__(self, pause=0, figsize=None, **kw):\n",
    "        super().__init__(**kw)\n",
    "        \n",
    "        self.figsize = figsize # desired figure size        \n",
    "        self.fig = None        # figure handle, may have several subplots        \n",
    "        self.ax0 = None        # Grid subplot handle\n",
    "        \n",
    "        self.pause = pause     # pause to slow animaiton\n",
    "        self.arrows = None     # policy arrows (direction of action with max value)\n",
    "        \n",
    "        # assuming env is not dynamic, otherwise should be moved to render() near self.to_pos(self.s)\n",
    "        self.start = self.to_pos(self.s0)         \n",
    "        self.goal1 = self.to_pos(self.goals[0])\n",
    "        self.goal2 = self.to_pos(self.goals[1])\n",
    "        self.cmap = colors.ListedColormap(['w', 'darkgray'])\n",
    "\n",
    "    # state representation function that converts 1-d list of state representation into a 2-d coordinates\n",
    "    def to_pos(self, s):\n",
    "        return [s%self.cols + 1, s//self.cols + 1]\n",
    "\n",
    "    #------------------------------------------initialise------------------------------------------------- \n",
    "    def init_cells(self, cells): \n",
    "        Cells = np.zeros((self.rows+1, self.cols+1),  dtype=bool)\n",
    "        Cells[0,0] = True # to populate for drawing \n",
    "        poses = self.to_pos(np.array(cells))\n",
    "        Cells[poses[1], poses[0]] = True\n",
    "        return Cells[1:,1:]\n",
    "    \n",
    "    #------------------------------------------render ✍️-------------------------------------------------\n",
    "    # this function is to protect render() called twice for Gridi\n",
    "    def render(self, **kw):\n",
    "        self.render__(**kw)\n",
    "\n",
    "    # we have placed most of the render overhead in the render() function to keep the rest efficient.\n",
    "    # this funciton must not be called directly instead render() is to be called\n",
    "    def render__(self, underhood='', pause=None, label='', subplot=131, large=False, \n",
    "               animate=True, image=False, saveimg=False,  **kw):\n",
    "        \n",
    "        if self.figsize is None:\n",
    "            if   self.rows==1:             self.figsize = (15,.5) \n",
    "            elif underhood=='Q':           self.figsize = (20, 10)\n",
    "            elif underhood=='V' and large: self.figsize = (30, 25)\n",
    "            else:                          self.figsize = (17, 3)\n",
    "        if image: self.figsize = (17, 3) # changing the default figure size is dissallowed for games\n",
    "\n",
    "        if self.fig is None: self.fig = plt.figure(1)\n",
    "        #if self.ax0 is None: self.ax0 = plt.subplot(subplot)\n",
    "        plt.gcf().set_size_inches(self.figsize[0], self.figsize[1])\n",
    "            \n",
    "        #if   animate: self.ax0 = plt.subplot(subplot)\n",
    "        #elif image:   plt.cla() \n",
    "        self.ax0 = plt.subplot(subplot)\n",
    "        if image and not animate: plt.cla()\n",
    "           \n",
    "        \n",
    "        # get hooks for self properties\n",
    "        rows, cols = self.rows, self.cols\n",
    "        pos, start, goal1, goal2 = self.to_pos(self.s), self.start, self.goal1, self.goal2\n",
    "        \n",
    "        pause = self.pause if pause is None else pause\n",
    "        \n",
    "        # a set of properties for the grid subplot\n",
    "        \n",
    "        prop = {'xticks': np.linspace(0, cols, cols+1),     'xticklabels':[],\n",
    "                'yticks': np.linspace(0, rows, rows+1)+.01, 'yticklabels':[],\n",
    "                'xlim':(0, cols), 'ylim':(0, rows), 'xlabel': label} # useful info\n",
    "        self.ax0.update(prop)\n",
    "        self.ax0.tick_params(bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "        if self.style not in ['maze', 'cliff']: self.ax0.grid(True)\n",
    "\n",
    "        # robot visuals :-)\n",
    "        mrgn = .5\n",
    "        eyes = '˚-˚' if underhood!='Q' else '' \n",
    "        body = 'ro'  if underhood!='Q' else 'co'\n",
    "        \n",
    "        # plot goals and start state\n",
    "        for (x,y), s in zip([goal1, goal2, start], ['G', 'G', 'S']):\n",
    "            self.ax0.text(x-mrgn, y-mrgn, s, fontsize=20)\n",
    "        \n",
    "        # plot robot\n",
    "        self.ax0.text(pos[0]-mrgn-.2, pos[1]-mrgn-.15, eyes, fontsize=10)\n",
    "        self.ax0.plot(pos[0]-mrgn,    pos[1]-mrgn,     body, markersize=15) \n",
    "        #self.ax0.plot(pos, body, markersize=15) # this causes the body not be up to date in later lessons\n",
    "\n",
    "        # to reduce overhead, pre-store coordinates in the grid only when render is needed\n",
    "        if self.X is None: \n",
    "            self.X, self.Y = np.array(self.to_pos(np.arange(self.nS))) \n",
    "            self.Ox, self.Oy = np.arange(cols+1), np.arange(rows+1)\n",
    "\n",
    "        # underhood obstacles and a cliffs\n",
    "        if self.style=='maze':  \n",
    "            if self.Obstacles is None: self.Obstacles = self.init_cells(self.obstacles)\n",
    "            self.ax0.pcolormesh(self.Ox, self.Oy, self.Obstacles, edgecolors='lightgray', cmap=self.cmap)\n",
    "        \n",
    "        # this means that the user wants to draw the policy arrows (actions)\n",
    "        if 'Q' in kw and underhood=='': underhood='maxQ'\n",
    "        \n",
    "        # a placeholder function for extra rendering jobs\n",
    "        render_ = getattr(self, 'render_'+ underhood)(**kw)\n",
    "        # windy style needs a bespoke rendering\n",
    "        if self.style =='windy': self.render_windy()\n",
    "\n",
    "        if image: self.render_image(saveimg=saveimg)\n",
    "            \n",
    "        # to animate clear and plot the Grid\n",
    "        if animate: clear_output(wait=True); plt.show(); time.sleep(pause)\n",
    "        #else: plt.subplot(subplot)\n",
    "    \n",
    "    #-------------------------helper functions for rendering policies and value functions---------------------\n",
    "    def render_(self, **kw):\n",
    "        pass # a placeholder for a another drawing if needed\n",
    "    \n",
    "    def render_image(self, **kw):\n",
    "        pass # a placeholder for capturing and saving Grid as images\n",
    "    \n",
    "    # renders all states numbers' reprsentation on the grid\n",
    "    def render_states(self, **kw):\n",
    "        X,Y  = self.X, self.Y\n",
    "        for s in range(self.nS): \n",
    "            self.ax0.text(X[s]-.5,Y[s]-.5, s, fontsize=13, color='g')\n",
    "\n",
    "class Grid(Grid):\n",
    "    def __init__(self, reward='',  style='', **kw):\n",
    "        super().__init__(**kw)\n",
    "    \n",
    "        # explicit rewards for[intermediate,goal0,goal1, cliff] states\n",
    "        self.reward_    = [0,    1,   0, -100] # this is the default value for the rewards\n",
    "        self.randwalk   = [ 0,   0,   1,    0]\n",
    "        self.randwalk_  = [ 0,  -1,   1,    0]\n",
    "        self.reward0    = [-1,   0,   0,   -1]\n",
    "        self.reward_1   = [-1,  -1,  -1,   -1]\n",
    "        self.reward1    = [-1,   1,   1,   -1]\n",
    "        self.reward10   = [-1,  10,  10,   -1]\n",
    "        self.reward100  = [-1, 100, 100,   -1]\n",
    "    \n",
    "        if reward: self.rewards  = getattr(self, reward)\n",
    "        self.style = style\n",
    "        \n",
    "        # accommodating grids styles -------------------------------------------------------------\n",
    "        self.X, self.Y = None, None\n",
    "        self.Obstacles = self.Cliffs = 0 # np arrays for display only, related to self.obstacles, self.cliffs\n",
    "        self.wind = [0]*10               # [0,0,0,0,0,0,0,0,0,0]\n",
    "        \n",
    "        if self.style=='maze':\n",
    "            self.Obstacles = None        # for displaying only, to be filled when render() is called\n",
    "            rows = self.rows\n",
    "            cols = self.cols\n",
    "            midc = int(cols/2)\n",
    "            \n",
    "            ## WALLS\n",
    "            #######################\n",
    "            #######################\n",
    "            #######################\n",
    "            # Assign the obstacles list to the instance variable\n",
    "            self.obstacles = obstacles\n",
    "        # upward winds intensity for each column\n",
    "        elif self.style=='windy':\n",
    "            self.wind = [0,0,0,1,1,1,2,2,1,0] # as in example 6.5 of the book\n",
    "    \n",
    "    # override the step() function so that it can deal with wind\n",
    "    def step(self, a, *args):\n",
    "        a = self.actions[a]\n",
    "        if not self.invalid(self.s,a): self.s += a\n",
    "        \n",
    "        if self.style=='windy':\n",
    "            maxwind = self.wind[self.s%self.cols]\n",
    "            for wind in range(maxwind, 0, -1): # we need to try apply all the wind or at least part of it\n",
    "                if not self.invalid(self.s, wind*self.cols): self.s += wind*self.cols; break\n",
    "        \n",
    "        self.trace.append(self.s)\n",
    "        reward, done = self.reward()       # must be done in this order for the cliff reset to work properly\n",
    "        return self.s_(), reward, done, {} # empty dict for compatibility\n",
    "    \n",
    "    def render_maxQ(self, Q=None, **kw): \n",
    "        if Q is None: Q=np.ones((self.nS, self.nA ))\n",
    "        X, Y = self.X, self.Y\n",
    "        if self.arrows is None: self.init_arrows()\n",
    "        U, Z = self.arrows[np.argmax(Q,1)].T\n",
    "        ind  = np.sum(Q,1)!=0\n",
    "        if ind.any()==False: return\n",
    "        plt.quiver(X[ind]-.5,Y[ind]-.5,  U[ind],Z[ind],color='b')\n",
    "        \n",
    "        \n",
    "    def init_arrows(self):       \n",
    "        self._left,      self._right,   self._down,       self._up       = tuple(range(0,4))\n",
    "        self._left_down, self._left_up, self._right_down, self._right_up = tuple(range(4,8))\n",
    "        \n",
    "        # works for quiver and pos, max action can potentially go upto 8! if we are dealing with a grid world\n",
    "        self.arrows = np.zeros((self.nA,2), dtype=int)\n",
    "        \n",
    "        self.arrows[self._left ] =[-1, 0]  # '←'\n",
    "        self.arrows[self._right] =[ 1, 0]  # '→'\n",
    "        \n",
    "        if self.nA>2:\n",
    "            self.arrows[self._down ] =[ 0,-1]  # '↓'\n",
    "            self.arrows[self._up   ] =[ 0, 1]  # '↑'\n",
    "\n",
    "        if self.nA>4:\n",
    "            self.arrows[self._left_down ]=[-1,-1]  # '↓←'\n",
    "            self.arrows[self._left_up   ]=[-1, 1]  # '↑←'\n",
    "            self.arrows[self._right_down]=[ 1,-1]  # '→↓'\n",
    "            self.arrows[self._right_up  ]=[ 1, 1]  # '→↑\n",
    "\n",
    "class MRP:\n",
    "    \n",
    "    def __init__(self, env=Grid(style='maze'), γ=1, α=.1, v0=0, episodes=100, view=1, \n",
    "                 store=False, # Majority of methods are pure one-step online and no need to store episodes trajectories \n",
    "                 max_t=2000, seed=None, visual=False, underhood='', \n",
    "                 last=10, print_=False):\n",
    "                \n",
    "\n",
    "        # hyper parameters\n",
    "        self.env = env\n",
    "        self.γ = γ\n",
    "        self.α = α # average methods(like MC1st) do not need this but many other methods (like MCα) do\n",
    "        self.v0 = v0\n",
    "        self.episodes = episodes\n",
    "        self.store = store\n",
    "        self.max_t = max_t\n",
    "        self.visual = visual\n",
    "        self.view = view\n",
    "        self.underhood = underhood\n",
    "        self.last = last\n",
    "        self.print = print_\n",
    "\n",
    "        # reference to two important functions\n",
    "        self.policy = self.stationary\n",
    "        self.step = self.step_a\n",
    "        # we might want to skip a step\n",
    "        self.skipstep = False\n",
    "        \n",
    "        nA = self.env.nA\n",
    "        self.As = list(range(nA))\n",
    "        self.pAs = [1/nA]*nA\n",
    "        \n",
    "        # useful to repeate the same experiement\n",
    "        self.seed(seed)\n",
    "        # to protect interact() in case of no training \n",
    "        self.ep = -1 \n",
    "        \n",
    "    # set up important metrics\n",
    "    def init_metrics(self):\n",
    "        self.Ts = np.zeros(self.episodes, dtype=np.uint32)\n",
    "        self.Rs = np.zeros(self.episodes)\n",
    "        self.Es = np.zeros(self.episodes)  \n",
    "        self.inds = np.ones (self.episodes, dtype=bool)\n",
    "        \n",
    "    # set up the V table\n",
    "    def init_(self):\n",
    "        self.V = np.ones(self.env.nS)*self.v0\n",
    "\n",
    "    \n",
    "    # useful for inheritance, gives an expected return (value) for state s\n",
    "    def V_(self, s=None): \n",
    "        return self.V  if s is None else self.V[s]\n",
    "    \n",
    "    def seed(self, seed=None, **kw):\n",
    "        if seed is not None: np.random.seed(seed); random.seed(seed)\n",
    "    #-------------------------------------------buffer related-------------------------------------------------\n",
    "    # The buffer get reinitialised by reinitialising t only but we have to be careful not to exceed t+1 at any time\n",
    "    def allocate(self): \n",
    "        if not self.store: return\n",
    "        self.r = np.zeros(self.max_t)\n",
    "        self.s = np.ones(self.max_t, dtype=np.uint32)*(self.env.nS+10) # states are indices:*(nS+10)for debugging \n",
    "        self.a = np.ones(self.max_t, dtype=np.uint32)*(self.env.nA+10) #actions are indices:*(nA+10)for debugging       \n",
    "        self.done = np.zeros(self.max_t, dtype=bool)\n",
    "    \n",
    "    def store_(self, s=None,a=None,rn=None,sn=None,an=None, done=None, t=0):\n",
    "        if not self.store: return\n",
    "        \n",
    "        if s  is not None: self.s[t] = s\n",
    "        if a  is not None: self.a[t] = a\n",
    "        if rn is not None: self.r[t+1] = rn\n",
    "        if sn is not None: self.s[t+1] = sn\n",
    "        if an is not None: self.a[t+1] = an\n",
    "        if done is not None: self.done[t+1] = done\n",
    "    \n",
    "    def stop_ep(self, done):\n",
    "        return done or (self.store and self.t+1 >= self.max_t-1) # goal reached or storage is full\n",
    "    \n",
    "    # ------------------------------------ experiments related --------------------------------------------\n",
    "    def stop_exp(self):\n",
    "        if self.stop_early(): print('experience stopped at episode %d'%self.ep); return True\n",
    "        return self.ep == self.episodes - 1\n",
    "\n",
    "    #----------------------------------- 🐾steps as per the algorithm style --------------------------------\n",
    "    def step_0(self):\n",
    "        s = self.env.reset()                                 # set env/agent to the start position\n",
    "        a = self.policy(s)\n",
    "        return s,a\n",
    "    \n",
    "    # accomodates Q-learning and V style algorithms\n",
    "    def step_a(self, s,_, t):                          \n",
    "        if self.skipstep: return 0, None, None, None, True\n",
    "        a = self.policy(s)\n",
    "    \n",
    "        sn, rn, done, _ = self.env.step(a)\n",
    "    \n",
    "        # we added s=s for compatibility with deep learning\n",
    "        self.store_(s=s, a=a, rn=rn, sn=sn, done=done, t=t)\n",
    "    \n",
    "        # None is returned for compatibility with other algorithms\n",
    "        return rn,sn, a,None, done\n",
    "    \n",
    "    # accomodates Sarsa style algorithms\n",
    "    def step_an(self, s,a, t):                          \n",
    "        if self.skipstep: return 0, None, None, None, True\n",
    "        sn, rn, done, _ = self.env.step(a)\n",
    "\n",
    "        an = self.policy(sn)\n",
    "        # env.step(a)\n",
    "        # print(self.episodes)\n",
    "        \n",
    "        # we added s=s for compatibility with deep learning later\n",
    "        self.store_(s=s, a=a, rn=rn, sn=sn, an=an, done=done, t=t)\n",
    "        return rn,sn, a,an, done\n",
    "    \n",
    "    #------------------------------------ 🌖 online learning and interaction --------------------------------\n",
    "    def interact(self, train=True, grid_img=False, **kw):\n",
    "        if train:\n",
    "            self.init_()\n",
    "            self.init()                                     # user defined init() before all episodes\n",
    "            self.init_metrics()\n",
    "            self.allocate()\n",
    "            self.plot0()                                    # useful to see initial V values\n",
    "            self.seed(**kw)\n",
    "            self.ep = -1 #+ (not train)*(self.episodes-1)\n",
    "            self.t_ = 0                                     # steps counter for all episodes\n",
    "        \n",
    "        #for self.ep in range(self.episodes):\n",
    "        while not self.stop_exp():\n",
    "            self.ep += 1\n",
    "            self.t  = -1                                    # steps counter for curr episode\n",
    "            self.Σr = 0\n",
    "            done = False\n",
    "            # initial step\n",
    "            s,a = self.step_0()\n",
    "            self.step0()                                    # user defined init of each episode\n",
    "            # an episode is a set of steps, interact and learn from experience, online or offline.\n",
    "            while not self.stop_ep(done):\n",
    "        \n",
    "                # take one step\n",
    "                self.t += 1\n",
    "                self.t_+= 1\n",
    "                \n",
    "                rn,sn, a,an, done = self.step(s,a, self.t)  # takes a step in env and store tarjectory if needed\n",
    "                self.online(s, rn,sn, done, a,an) # to learn online, pass a one step trajectory\n",
    "\n",
    "                if self.ep == 199:\n",
    "                    print(self.t)\n",
    "                    print(a)\n",
    "                    env.step(a)\n",
    "                \n",
    "                self.Σr += rn\n",
    "                self.rn = rn\n",
    "                s,a = sn,an\n",
    "                \n",
    "                # render last view episodes, for games ep might>episodes\n",
    "                if self.visual and self.episodes > self.ep >= self.episodes-self.view: self.render(**kw)\n",
    "\n",
    "            # to learn offline and plot episode\n",
    "            self.metrics()\n",
    "            self.offline()\n",
    "            self.plot_ep()\n",
    "            \n",
    "    \n",
    "        # plot experience   \n",
    "        self.plot_exp(**kw)\n",
    "        \n",
    "        return self  \n",
    "    #------------------------------------- policies types 🧠-----------------------------------\n",
    "        \n",
    "    def stationary(self, *args):\n",
    "        #return choice(self.As, 1, p=self.pAs)[0] # this gives better experiements quality but is less efficient\n",
    "        return choices(self.As, weights=self.pAs, k=1)[0] if self.env.nA!=2 else np.random.binomial(1, 0.5)\n",
    "    \n",
    "    #---------------------------------------perfromance metrics📏 ------------------------------\n",
    "    def metrics(self):\n",
    "        # we use %self.episodes so that when we use a different criterion to stop_exp() code will run\n",
    "        self.Ts[self.ep%self.episodes] = self.t+1\n",
    "        self.Rs[self.ep%self.episodes] = self.Σr\n",
    "        self.Es[self.ep%self.episodes] = self.Error()\n",
    "        \n",
    "        if self.print: print(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        # mean works regardless of where we stored the episode metrics (we use %self.episodes)\n",
    "        ep, episodes = self.ep, self.episodes\n",
    "        i, inds = ep%episodes, self.inds.copy()\n",
    "        last = min(ep+1, self.last) # display last 10 episodes or so\n",
    "        inds[i+1: episodes+1-(last-i)] = False # turn off indexes that we do not want, to deal with circular indexes\n",
    "        \n",
    "        metrics = 'step %d, episode %d, r %.2f, mean r last %d ep %.2f, ε %.2f'\n",
    "        values = (self.t_, ep, self.Rs[i], last, self.Rs[inds][-last:].mean().round(2), round(self.ε, 2))\n",
    "\n",
    "        return metrics%values\n",
    "\n",
    "    #------------------------functions that can be overridden in the child class-----------------\n",
    "    def init(self):\n",
    "        pass\n",
    "    def step0(self):\n",
    "        pass\n",
    "    def Error(self):\n",
    "        return 0\n",
    "    def stop_early(self):\n",
    "        return False\n",
    "    def plot0(self):\n",
    "        pass\n",
    "    def plot_t(self):\n",
    "        pass\n",
    "    def plot_ep(self):\n",
    "        pass\n",
    "    def plot_exp(self, *args):\n",
    "        pass\n",
    "    def offline(self):\n",
    "        pass\n",
    "    def online(self,*args):\n",
    "        pass\n",
    "    #---------------------------------------visualise ✍️----------------------------------------\n",
    "    # overload the env render function\n",
    "    def render(self, rn=None, label='', **kw):\n",
    "        if rn is None: rn=self.rn\n",
    "        param = {'V':self.V_()} if self.underhood=='V' else {}\n",
    "        self.env.render(**param, \n",
    "                        label=label+' reward=%d, t=%d, ep=%d'%(rn, self.t+1, self.ep+1), \n",
    "                        underhood=self.underhood, \n",
    "                        **kw)\n",
    "\n",
    "class MRP(MRP):\n",
    "    \n",
    "    def __init__(self, plotV=False,  plotT=False, plotR=False, plotE=False, animate=False, Vstar=None, **kw):\n",
    "        super().__init__(**kw)\n",
    "        \n",
    "        # visualisation related\n",
    "        self.plotT = plotT\n",
    "        self.plotR = plotR\n",
    "        self.plotE = plotE\n",
    "        self.plotV = plotV \n",
    "        self.animate = animate\n",
    "        self.eplist = []\n",
    "        \n",
    "        nS = self.env.nS\n",
    "        self.Vstar = Vstar if Vstar is not None else self.env.Vstar\n",
    "    #------------------------------------------- metrics📏 -----------------------------------------------  \n",
    "    # returns RMSE but can be overloaded if necessary\n",
    "    # when Vstar=0, it shows how V is evolving via training \n",
    "    def Error(self):\n",
    "        if self.Vstar is None: return 0\n",
    "        return np.sqrt(np.mean(((self.V_() - self.Vstar)[1:-1])**2)) #if self.Vstar is not None else 0\n",
    "    \n",
    "    #--------------------------------------------visualise ✍️----------------------------------------------\n",
    "\n",
    "    def plot0(self):\n",
    "        if self.plotV: self.plot_V(); plt.show()\n",
    "        \n",
    "    def plot_exp(self, label='', **kw):\n",
    "        self.plot_ep(animate=True, plot_exp=True, label=label)\n",
    "        \n",
    "    def plot_ep(self, animate=None, plot_exp=False, label=''): \n",
    "        if len(self.eplist)< self.episodes: self.eplist.append(self.ep+1)\n",
    "            \n",
    "        if animate is None: animate = self.animate\n",
    "        if not animate: return\n",
    "        frmt='.--'if not plot_exp or self.ep==0 else '--'\n",
    " \n",
    "        if self.visual: \n",
    "            if self.ep==self.episodes-1: self.render(animate=False) # shows the policy \n",
    "            else:                        self.env.render(animate=False) \n",
    "        if self.plotV:  self.plot_V(ep=self.ep+1)        \n",
    "        \n",
    "        i=2\n",
    "        for plot, ydata, label_ in zip([self.plotT, self.plotR, self.plotE], \n",
    "                                      [self.Ts,    self.Rs,    self.Es   ], \n",
    "                                      ['steps   ', 'Σrewards', 'Error   ']):\n",
    "            if not plot: continue\n",
    "            plt.subplot(1,3,min(i,3)).plot(self.eplist[:self.ep+1], ydata[:self.ep+1], frmt, label=label_+label)\n",
    "            plt.xlabel('episodes')\n",
    "            plt.legend()\n",
    "            i+=1\n",
    "\n",
    "        if self.visual or self.plotV or self.plotT or self.plotR or self.plotE:\n",
    "            figsize = plt.gcf().get_size_inches()\n",
    "            plt.gcf().set_size_inches(max(figsize[0],18), figsize[1])\n",
    "            clear_output(wait=True)\n",
    "            if not plot_exp: plt.show()\n",
    "\n",
    "\n",
    "    def plot_V(self, ep=0):\n",
    "        \n",
    "        self.env.ax0 = plt.subplot(1,3,1) # to add this axis next to a another axis to save some spaces\n",
    "        plt.gcf().set_size_inches(18, 3)\n",
    "        \n",
    "        # get letter as state names if no more than alphabet else just give them numbers\n",
    "        letters = self.env.letters_list()[1:-1] if self.env.nS<27 else list(range(self.env.nS-2))\n",
    "        \n",
    "        # plot the estimated values against the optimal values\n",
    "        plt.plot(letters, self.V_()[1:-1], '.-', label='V episode=%d'%(ep)) # useful for randwalk\n",
    "        plt.plot(letters, self.Vstar[1:-1],'.-k')\n",
    "        \n",
    "        # set up the figure\n",
    "        plt.xlabel('State', fontsize=16)\n",
    "        plt.legend()\n",
    "        plt.title('Estimated value for %d non-terminal states'%(self.env.nS-2), fontsize=16)\n",
    "        plt.gca().spines['right'].set_visible(False)\n",
    "        plt.gca().spines['top'].set_visible(False)\n",
    "\n",
    "def MDP(MRP=MRP):\n",
    "    class MDP(MRP):\n",
    "        def __init__(self, env=Grid(style='maze'), commit_ep=0, ε=.1, εmin=0.01, dε=1, εT=0, q0=0, Tstar=0, **kw): \n",
    "\n",
    "            super().__init__(env=env, **kw)\n",
    "            # set up hyper parameters\n",
    "            self.ε = ε \n",
    "            self.ε0 = ε  # store initial \n",
    "            self.dε = dε # for exp decay\n",
    "            self.εT = εT # for lin decay\n",
    "            self.εmin = εmin\n",
    "            \n",
    "            # override the policy to εgreedy to make control possible\n",
    "            self.policy = self.εgreedy\n",
    "\n",
    "            # initial Q values\n",
    "            self.q0 = q0\n",
    "\n",
    "            # which episode to commit changes\n",
    "            self.commit_ep = commit_ep\n",
    "            \n",
    "            # number of steps for optimal policy\n",
    "            self.Tstar = Tstar\n",
    "            \n",
    "        # set up the Q table\n",
    "        def init_(self):\n",
    "            super().init_() # initialises V\n",
    "            self.Q = np.ones((self.env.nS,self.env.nA))*self.q0\n",
    "        \n",
    "        #------------------------------------- add some more policies types 🧠-------------------------------\n",
    "        # useful for inheritance, gives us a vector of actions values\n",
    "        def Q_(self, s=None, a=None):\n",
    "            return self.Q[s] if s is not None else self.Q\n",
    "        \n",
    "\n",
    "        # returns a pure greedy action, **not to be used in learning**\n",
    "        def greedy_(self, s):\n",
    "            return np.argmax(self.Q_(s))\n",
    "        \n",
    "        # greedy stochastic MaxQ\n",
    "        def greedy(self, s): \n",
    "            self.isamax = True\n",
    "            # instead of return np.argmax(Q[s]) get all max actions and return one of the max actions randomly\n",
    "            Qs = self.Q_(s)\n",
    "            #print(Qs)\n",
    "            if Qs.shape[0]==1: raise ValueError('something might be wrong number of actions ==1')\n",
    "            return choices(np.where(Qs==Qs.max())[0])[0] # more efficient than choice\n",
    "            #return choice(np.where(Qs==Qs.max())[0])\n",
    "\n",
    "        # returns a greedy action most of the time\n",
    "        def εgreedy(self, s):\n",
    "            # there is pr=ε/nA that a max action is chosen but is not considerd max, we ignored it in favour of efficiency\n",
    "            self.isamax = False \n",
    "            if self.dε < 1: self.ε = max(self.εmin, self.ε*self.dε)              # exponential decay\n",
    "            if self.εT > 0: self.ε = max(self.εmin, self.ε0 - self.t_ / self.εT) # linear      decay\n",
    "            \n",
    "            return self.greedy(s) if rand() > self.ε else randint(0, self.env.nA)\n",
    "    \n",
    "        # returns the policy probabilities (of selecting a specific action)\n",
    "        def π(self, sn,  a=None):\n",
    "            ε, nA, Qsn = self.ε, self.env.nA, self.Q_(sn)\n",
    "            π_ = Qsn*0 + ε/nA\n",
    "            π_[Qsn.argmax()] += 1-ε\n",
    "            return π_ if a is None else π_[a]\n",
    "\n",
    "        # returns whether the current policy is optimal by checking if agent can reach the goal in self.Tstar\n",
    "        def πisoptimal(self):\n",
    "            s = self.env.reset()\n",
    "            done = False\n",
    "            for t in range(self.Tstar):\n",
    "                s,_, done,_ = self.env.step(self.greedy_(s))\n",
    "            return done\n",
    "\n",
    "        #---------------------------------------visualise ✍️----------------------------------------\n",
    "        # override the render function\n",
    "        def render(self, rn=None, label='', **kw):\n",
    "            if rn is None: rn=self.rn\n",
    "            param = {'Q':self.Q_()} if 'Q' in self.underhood else {} # 'maxQ' or 'Q'\n",
    "            self.env.render(**param, \n",
    "                            label=label+' reward=%d, t=%d, ep=%d'%(rn, self.t+1, self.ep+1), \n",
    "                            underhood=self.underhood, **kw)\n",
    "    \n",
    "    return MDP\n",
    "\n",
    "class Sarsa(MDP()):\n",
    "    \n",
    "    def init(self): #α=.8\n",
    "        self.step = self.step_an # for Sarsa we want to decide the next action in time step t\n",
    "        self.count = 0\n",
    "    \n",
    "    # ----------------------------------------🌖 online learning ----------------------------------------\n",
    "    def online(self, s, rn,sn, done, a,an):\n",
    "        self.Q[s,a] += self.α*(rn + (1- done)*self.γ*self.Q[sn,an] - self.Q[s,a])\n",
    "        self.count = self.count + 1\n",
    "\n",
    "demoT = {'plotT':True, 'visual':True, 'underhood':'maxQ'}                 # suitable for control\n",
    "demoR = {'plotR':True, 'visual':True, 'underhood':'maxQ'}                 # suitable for control\n",
    "demoTR= {'plotT':True, 'plotR':True, 'visual':True, 'underhood':'maxQ'}   # suitable for control\n",
    "demoQ = demoT # alias\n",
    "\n",
    "def demo(what='V'):\n",
    "    switch = {\n",
    "        'V':    {'plotE':True, 'plotV':True, 'animate':True},                    # suitable for prediction\n",
    "        'T':    {'plotT':True, 'visual':False, 'underhood':'maxQ'},               # suitable for control\n",
    "        'R':    {'plotR':True, 'visual':True, 'underhood':'maxQ'},               # suitable for control\n",
    "        'TR':   {'plotT':True, 'plotR':True, 'visual':True,'underhood':'maxQ'},  # suitable for control\n",
    "        'Game': {'plotT':True, 'plotR':True, 'visual':True, 'animate':True}      # suitable for games\n",
    "    }\n",
    "    return switch.get(what,{})\n",
    "def demoV(): return demo('V')\n",
    "def demoT(): return demo('T')\n",
    "def demoQ(): return demo('T')# alias\n",
    "def demoR(): return demo('R')\n",
    "def demoTR(): return demo('TR')\n",
    "def demoGame(): return demo('Game')\n",
    "\n",
    "\n",
    "print('started')\n",
    "sarsa = Sarsa(Grid(style='maze', figsize=(80, 20)), α=0.1, episodes=200, seed=8, **demoQ()).interact()\n",
    "print('finished')\n",
    "\n",
    "env.stop()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e353011e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
